{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/jjshoots/bsuite.git@f8d81b2\n",
    "from bsuite import sweep\n",
    "import bsuite\n",
    "import os\n",
    "from rllib_wrapper import RLLibEnv\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray import air\n",
    "from ray import tune\n",
    "from ray.tune.registry import register_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "from bsuite import sweep\n",
    "envs = []\n",
    "for i in range(0,len(sweep.SWEEP),1):\n",
    "    if sweep.SWEEP[i].split('/')[0] not in envs:\n",
    "        #if not 'scale' in sweep.SWEEP[i].split('/')[0]:\n",
    "        envs.append(sweep.SWEEP[i].split('/')[0])\n",
    "env_strings = []\n",
    "for s in ['1', '5', '10', '15']:\n",
    "    for e in envs:\n",
    "        env_strings.append(e+'/'+s)\n",
    "print(len(env_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 12:14:00,061\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[97mLoaded bsuite_id: cartpole_swingup/1.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/adamprice/RLOlympics/results/PPO/data.db'\n",
    "env_str = 'cartpole_swingup/1'\n",
    "if not os.path.exists(path):\n",
    "   os.makedirs(path)\n",
    "\n",
    "env = bsuite.load_from_id(env_str)\n",
    "\n",
    "def env_creator(env_config):\n",
    "    env = bsuite.load_and_record_to_sqlite(env_str, db_path=path)\n",
    "    env = bsuite.load_from_id(env_str)\n",
    "    return RLLibEnv(env)\n",
    "\n",
    "import ray\n",
    "ray.rllib.utils.check_env(RLLibEnv(env))\n",
    "\n",
    "register_env(name=env_str.replace('/','_'), env_creator=env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-07-18 13:49:58</td></tr>\n",
       "<tr><td>Running for: </td><td>00:05:33.48        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.8/16.0 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 7.0/12 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 5<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                         </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00000</td><td style=\"text-align: right;\">           1</td><td>/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00000_0_lr=0.0100,train_batch_size=64_2023-07-18_13-44-25/error.txt  </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00004</td><td style=\"text-align: right;\">           1</td><td>/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00004_4_lr=0.0010,train_batch_size=128_2023-07-18_13-44-25/error.txt </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00005</td><td style=\"text-align: right;\">           1</td><td>/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00005_5_lr=0.0005,train_batch_size=128_2023-07-18_13-44-25/error.txt </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00007</td><td style=\"text-align: right;\">           1</td><td>/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00007_7_lr=0.0010,train_batch_size=256_2023-07-18_13-44-25/error.txt </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00011</td><td style=\"text-align: right;\">           1</td><td>/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00011_11_lr=0.0005,train_batch_size=512_2023-07-18_13-44-25/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00001</td><td>RUNNING </td><td>127.0.0.1:95630</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">  1081</td><td style=\"text-align: right;\">       247.532  </td><td style=\"text-align: right;\">69184</td><td style=\"text-align: right;\"> -2.54571 </td><td style=\"text-align: right;\">                 0  </td><td style=\"text-align: right;\">               -57.7</td><td style=\"text-align: right;\">           982.971</td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00002</td><td>RUNNING </td><td>127.0.0.1:95631</td><td style=\"text-align: right;\">0.0005</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">  1084</td><td style=\"text-align: right;\">       249.452  </td><td style=\"text-align: right;\">69376</td><td style=\"text-align: right;\"> -4.43973 </td><td style=\"text-align: right;\">                 0  </td><td style=\"text-align: right;\">               -49.3</td><td style=\"text-align: right;\">           938.493</td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00003</td><td>RUNNING </td><td>127.0.0.1:95632</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">   598</td><td style=\"text-align: right;\">       272.088  </td><td style=\"text-align: right;\">76544</td><td style=\"text-align: right;\"> -0.623684</td><td style=\"text-align: right;\">                 0  </td><td style=\"text-align: right;\">               -35.8</td><td style=\"text-align: right;\">           995.25 </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00006</td><td>RUNNING </td><td>127.0.0.1:95635</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">   322</td><td style=\"text-align: right;\">       287.458  </td><td style=\"text-align: right;\">82432</td><td style=\"text-align: right;\"> -0.917857</td><td style=\"text-align: right;\">                 0  </td><td style=\"text-align: right;\">               -40.9</td><td style=\"text-align: right;\">           977.583</td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00008</td><td>RUNNING </td><td>127.0.0.1:95637</td><td style=\"text-align: right;\">0.0005</td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">   320</td><td style=\"text-align: right;\">       287.604  </td><td style=\"text-align: right;\">81920</td><td style=\"text-align: right;\"> -3.75172 </td><td style=\"text-align: right;\">                 0  </td><td style=\"text-align: right;\">               -51.7</td><td style=\"text-align: right;\">           935.345</td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00009</td><td>RUNNING </td><td>127.0.0.1:95638</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">               512</td><td style=\"text-align: right;\">   166</td><td style=\"text-align: right;\">       296.648  </td><td style=\"text-align: right;\">84992</td><td style=\"text-align: right;\"> -2.44615 </td><td style=\"text-align: right;\">                 0  </td><td style=\"text-align: right;\">               -57.4</td><td style=\"text-align: right;\">           928.286</td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00010</td><td>RUNNING </td><td>127.0.0.1:95639</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">               512</td><td style=\"text-align: right;\">   166</td><td style=\"text-align: right;\">       296.817  </td><td style=\"text-align: right;\">84992</td><td style=\"text-align: right;\"> -1.92674 </td><td style=\"text-align: right;\">                 0  </td><td style=\"text-align: right;\">               -54.7</td><td style=\"text-align: right;\">           976.721</td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00000</td><td>ERROR   </td><td>127.0.0.1:95629</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">        16.5752 </td><td style=\"text-align: right;\"> 3840</td><td style=\"text-align: right;\"> -5.45    </td><td style=\"text-align: right;\">                 0  </td><td style=\"text-align: right;\">               -17.3</td><td style=\"text-align: right;\">           482.833</td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00004</td><td>ERROR   </td><td>127.0.0.1:95633</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         5.18216</td><td style=\"text-align: right;\">  896</td><td style=\"text-align: right;\">nan       </td><td style=\"text-align: right;\">               nan  </td><td style=\"text-align: right;\">               nan  </td><td style=\"text-align: right;\">           nan    </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00005</td><td>ERROR   </td><td>127.0.0.1:95634</td><td style=\"text-align: right;\">0.0005</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         5.18741</td><td style=\"text-align: right;\">  896</td><td style=\"text-align: right;\">nan       </td><td style=\"text-align: right;\">               nan  </td><td style=\"text-align: right;\">               nan  </td><td style=\"text-align: right;\">           nan    </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00007</td><td>ERROR   </td><td>127.0.0.1:95636</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         4.61347</td><td style=\"text-align: right;\">  768</td><td style=\"text-align: right;\">nan       </td><td style=\"text-align: right;\">               nan  </td><td style=\"text-align: right;\">               nan  </td><td style=\"text-align: right;\">           nan    </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00011</td><td>ERROR   </td><td>127.0.0.1:95640</td><td style=\"text-align: right;\">0.0005</td><td style=\"text-align: right;\">               512</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         6.06312</td><td style=\"text-align: right;\"> 1024</td><td style=\"text-align: right;\">-25.15    </td><td style=\"text-align: right;\">               -24.8</td><td style=\"text-align: right;\">               -25.5</td><td style=\"text-align: right;\">           387    </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPO pid=95638)\u001b[0m 2023-07-18 13:44:47,847\tWARNING algorithm_config.py:643 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(PPO pid=94275)\u001b[0m 2023-07-18 13:40:41,161\tINFO algorithm.py:536 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(PPO pid=94275)\u001b[0m 2023-07-18 13:40:41,173\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(PPO pid=94275)\u001b[0m 2023-07-18 13:40:41,291\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPO pid=95639)\u001b[0m \u001b[1m\u001b[97mLoaded bsuite_id: cartpole_swingup/1.\u001b[0m\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(PPO pid=95639)\u001b[0m \u001b[1m\u001b[33mLogging results to SQLite database in /Users/adamprice/RLOlympics/results/PPO/data.db.\u001b[0m\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>connector_metrics                                                                                                                                              </th><th>counters                                                                                                                            </th><th>custom_metrics  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th>info                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_sampled_throughput_per_sec</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained_throughput_per_sec</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                          </th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                    </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </th><th>timers                                                                                                                                                                                                            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00000</td><td style=\"text-align: right;\">                   3840</td><td>{&#x27;ObsPreprocessorConnector_ms&#x27;: 0.016121069590250652, &#x27;StateBufferConnector_ms&#x27;: 0.009250640869140625, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.24902423222859701}</td><td>{&#x27;num_env_steps_sampled&#x27;: 3840, &#x27;num_env_steps_trained&#x27;: 3840, &#x27;num_agent_steps_sampled&#x27;: 3840, &#x27;num_agent_steps_trained&#x27;: 3840}    </td><td>{}              </td><td style=\"text-align: right;\">           482.833</td><td>{}             </td><td style=\"text-align: right;\">                 0  </td><td style=\"text-align: right;\">            -5.45    </td><td style=\"text-align: right;\">               -17.3</td><td style=\"text-align: right;\">                   0</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 0.11014328710734844, &#x27;cur_kl_coeff&#x27;: 1.1102230246251568e-17, &#x27;cur_lr&#x27;: 0.01, &#x27;total_loss&#x27;: 0.00020812731236219406, &#x27;policy_loss&#x27;: 2.146698534488678e-06, &#x27;vf_loss&#x27;: 0.00020641650462494, &#x27;vf_explained_var&#x27;: -0.7508742809295654, &#x27;kl&#x27;: 8.762519196163036e-07, &#x27;entropy&#x27;: 0.0004409714504921188, &#x27;entropy_coeff&#x27;: 0.001}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 64.0, &#x27;num_grad_updates_lifetime&#x27;: 179.0, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 1.0}}, &#x27;num_env_steps_sampled&#x27;: 3840, &#x27;num_env_steps_trained&#x27;: 3840, &#x27;num_agent_steps_sampled&#x27;: 3840, &#x27;num_agent_steps_trained&#x27;: 3840}                                           </td><td style=\"text-align: right;\">                     3840</td><td style=\"text-align: right;\">                     3840</td><td style=\"text-align: right;\">                   3840</td><td style=\"text-align: right;\">                               64</td><td style=\"text-align: right;\">                                   182.326</td><td style=\"text-align: right;\">                   3840</td><td style=\"text-align: right;\">                               64</td><td style=\"text-align: right;\">                                   182.326</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                           64</td><td>{&#x27;cpu_util_percent&#x27;: 73.9, &#x27;ram_util_percent&#x27;: 56.8}                          </td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 0.9661069735963624, &#x27;mean_inference_ms&#x27;: 3.2034059297329525, &#x27;mean_action_processing_ms&#x27;: 0.309174309476905, &#x27;mean_env_wait_ms&#x27;: 0.25387105184804076, &#x27;mean_env_render_ms&#x27;: 0.0} </td><td>{&#x27;episode_reward_max&#x27;: 0.0, &#x27;episode_reward_min&#x27;: -17.299999999999976, &#x27;episode_reward_mean&#x27;: -5.449999999999995, &#x27;episode_len_mean&#x27;: 482.8333333333333, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 0, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-17.299999999999976, -7.19999999999999, -3.800000000000002, -3.1000000000000014, -1.3, 0.0], &#x27;episode_lengths&#x27;: [262, 179, 177, 277, 1001, 1001]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.9661069735963624, &#x27;mean_inference_ms&#x27;: 3.2034059297329525, &#x27;mean_action_processing_ms&#x27;: 0.309174309476905, &#x27;mean_env_wait_ms&#x27;: 0.25387105184804076, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: 0.016121069590250652, &#x27;StateBufferConnector_ms&#x27;: 0.009250640869140625, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.24902423222859701}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       </td><td>{&#x27;training_iteration_time_ms&#x27;: 245.463, &#x27;sample_time_ms&#x27;: 223.605, &#x27;load_time_ms&#x27;: 0.399, &#x27;load_throughput&#x27;: 160365.288, &#x27;learn_time_ms&#x27;: 21.04, &#x27;learn_throughput&#x27;: 3041.762, &#x27;synch_weights_time_ms&#x27;: 0.005}    </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00001</td><td style=\"text-align: right;\">                  68288</td><td>{&#x27;ObsPreprocessorConnector_ms&#x27;: 0.010343910991281702, &#x27;StateBufferConnector_ms&#x27;: 0.007828422214673914, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.20373904186746347}</td><td>{&#x27;num_env_steps_sampled&#x27;: 68288, &#x27;num_env_steps_trained&#x27;: 68288, &#x27;num_agent_steps_sampled&#x27;: 68288, &#x27;num_agent_steps_trained&#x27;: 68288}</td><td>{}              </td><td style=\"text-align: right;\">           982.71 </td><td>{}             </td><td style=\"text-align: right;\">                 0  </td><td style=\"text-align: right;\">            -2.58261 </td><td style=\"text-align: right;\">               -57.7</td><td style=\"text-align: right;\">                   0</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 0.010231672165294489, &#x27;cur_kl_coeff&#x27;: 2.5e-322, &#x27;cur_lr&#x27;: 0.001, &#x27;total_loss&#x27;: 1.1237959067026775e-06, &#x27;policy_loss&#x27;: 5.463759104410807e-08, &#x27;vf_loss&#x27;: 1.5982331357614992e-06, &#x27;vf_explained_var&#x27;: -0.5059420267740885, &#x27;kl&#x27;: 6.6617400849150465e-09, &#x27;entropy&#x27;: 0.0005314586063226064, &#x27;entropy_coeff&#x27;: 0.001}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 64.0, &#x27;num_grad_updates_lifetime&#x27;: 3200.0, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 1.0}}, &#x27;num_env_steps_sampled&#x27;: 68288, &#x27;num_env_steps_trained&#x27;: 68288, &#x27;num_agent_steps_sampled&#x27;: 68288, &#x27;num_agent_steps_trained&#x27;: 68288}                                              </td><td style=\"text-align: right;\">                    68288</td><td style=\"text-align: right;\">                    68288</td><td style=\"text-align: right;\">                  68288</td><td style=\"text-align: right;\">                               64</td><td style=\"text-align: right;\">                                   298.726</td><td style=\"text-align: right;\">                  68288</td><td style=\"text-align: right;\">                               64</td><td style=\"text-align: right;\">                                   298.726</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                           64</td><td>{&#x27;cpu_util_percent&#x27;: 71.1, &#x27;ram_util_percent&#x27;: 61.3}                          </td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 0.6756914902583627, &#x27;mean_inference_ms&#x27;: 2.317691340247989, &#x27;mean_action_processing_ms&#x27;: 0.23736929942888318, &#x27;mean_env_wait_ms&#x27;: 0.1603007769955959, &#x27;mean_env_render_ms&#x27;: 0.0} </td><td>{&#x27;episode_reward_max&#x27;: 0.0, &#x27;episode_reward_min&#x27;: -57.70000000000055, &#x27;episode_reward_mean&#x27;: -2.5826086956521896, &#x27;episode_len_mean&#x27;: 982.7101449275362, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 0, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-57.70000000000055, -22.700000000000053, -27.200000000000117, -39.40000000000039, -18.39999999999999, -4.999999999999998, -3.800000000000002, -0.7999999999999999, -0.2, -0.5, -0.2, -0.6, -0.7, 0.0, -0.1, 0.0, -0.2, 0.0, 0.0, 0.0, -0.1, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], &#x27;episode_lengths&#x27;: [963, 369, 492, 1001, 918, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.6756914902583627, &#x27;mean_inference_ms&#x27;: 2.317691340247989, &#x27;mean_action_processing_ms&#x27;: 0.23736929942888318, &#x27;mean_env_wait_ms&#x27;: 0.1603007769955959, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: 0.010343910991281702, &#x27;StateBufferConnector_ms&#x27;: 0.007828422214673914, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.20373904186746347}}                                                                                                                                                                                                                                                                                                                                                                                       </td><td>{&#x27;training_iteration_time_ms&#x27;: 209.339, &#x27;sample_time_ms&#x27;: 187.518, &#x27;load_time_ms&#x27;: 0.38, &#x27;load_throughput&#x27;: 168424.806, &#x27;learn_time_ms&#x27;: 21.02, &#x27;learn_throughput&#x27;: 3044.687, &#x27;synch_weights_time_ms&#x27;: 0.006}     </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00002</td><td style=\"text-align: right;\">                  68352</td><td>{&#x27;ObsPreprocessorConnector_ms&#x27;: 0.010213918156094022, &#x27;StateBufferConnector_ms&#x27;: 0.008903940518697103, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.19114878442552355}</td><td>{&#x27;num_env_steps_sampled&#x27;: 68352, &#x27;num_env_steps_trained&#x27;: 68352, &#x27;num_agent_steps_sampled&#x27;: 68352, &#x27;num_agent_steps_trained&#x27;: 68352}</td><td>{}              </td><td style=\"text-align: right;\">           937.625</td><td>{}             </td><td style=\"text-align: right;\">                 0  </td><td style=\"text-align: right;\">            -4.50139 </td><td style=\"text-align: right;\">               -49.3</td><td style=\"text-align: right;\">                   0</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 0.011282552654544512, &#x27;cur_kl_coeff&#x27;: 1.3e-322, &#x27;cur_lr&#x27;: 0.0005, &#x27;total_loss&#x27;: 5.476176738739014e-07, &#x27;policy_loss&#x27;: -1.30385160446167e-07, &#x27;vf_loss&#x27;: 1.5415620661466771e-06, &#x27;vf_explained_var&#x27;: -1.0, &#x27;kl&#x27;: 3.91929148626143e-09, &#x27;entropy&#x27;: 0.0008525302788863579, &#x27;entropy_coeff&#x27;: 0.001}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 64.0, &#x27;num_grad_updates_lifetime&#x27;: 3203.0, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 1.0}}, &#x27;num_env_steps_sampled&#x27;: 68352, &#x27;num_env_steps_trained&#x27;: 68352, &#x27;num_agent_steps_sampled&#x27;: 68352, &#x27;num_agent_steps_trained&#x27;: 68352}                                                               </td><td style=\"text-align: right;\">                    68352</td><td style=\"text-align: right;\">                    68352</td><td style=\"text-align: right;\">                  68352</td><td style=\"text-align: right;\">                               64</td><td style=\"text-align: right;\">                                   315.724</td><td style=\"text-align: right;\">                  68352</td><td style=\"text-align: right;\">                               64</td><td style=\"text-align: right;\">                                   315.724</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                           64</td><td>{&#x27;cpu_util_percent&#x27;: 68.7, &#x27;ram_util_percent&#x27;: 61.2}                          </td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 0.6801709463451503, &#x27;mean_inference_ms&#x27;: 2.3471078668506267, &#x27;mean_action_processing_ms&#x27;: 0.2397599056639813, &#x27;mean_env_wait_ms&#x27;: 0.15956884745481406, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 0.0, &#x27;episode_reward_min&#x27;: -49.30000000000043, &#x27;episode_reward_mean&#x27;: -4.501388888888911, &#x27;episode_len_mean&#x27;: 937.625, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 0, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-48.10000000000041, -49.30000000000043, -14.599999999999964, -35.70000000000024, -31.30000000000036, -35.600000000000236, -18.099999999999987, -26.70000000000011, -13.799999999999967, -14.099999999999966, -13.199999999999969, -6.5999999999999925, -3.3000000000000016, -3.0000000000000013, -3.0000000000000013, -0.5, -0.7, -2.800000000000001, -0.4, -0.1, -0.4, -0.30000000000000004, -0.1, -0.2, -0.30000000000000004, -0.2, 0.0, -0.1, -0.30000000000000004, 0.0, -0.1, -0.1, 0.0, -0.1, 0.0, -0.1, -0.1, 0.0, -0.2, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0], &#x27;episode_lengths&#x27;: [702, 754, 261, 564, 697, 636, 388, 657, 456, 657, 1001, 1001, 676, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.6801709463451503, &#x27;mean_inference_ms&#x27;: 2.3471078668506267, &#x27;mean_action_processing_ms&#x27;: 0.2397599056639813, &#x27;mean_env_wait_ms&#x27;: 0.15956884745481406, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: 0.010213918156094022, &#x27;StateBufferConnector_ms&#x27;: 0.008903940518697103, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.19114878442552355}}                                                                                                                                                                               </td><td>{&#x27;training_iteration_time_ms&#x27;: 207.51, &#x27;sample_time_ms&#x27;: 187.127, &#x27;load_time_ms&#x27;: 0.366, &#x27;load_throughput&#x27;: 174762.667, &#x27;learn_time_ms&#x27;: 19.667, &#x27;learn_throughput&#x27;: 3254.106, &#x27;synch_weights_time_ms&#x27;: 0.005}    </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00003</td><td style=\"text-align: right;\">                  76032</td><td>{&#x27;ObsPreprocessorConnector_ms&#x27;: 0.010656055651212993, &#x27;StateBufferConnector_ms&#x27;: 0.007565084256623921, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.19956262488114207}</td><td>{&#x27;num_env_steps_sampled&#x27;: 76032, &#x27;num_env_steps_trained&#x27;: 76032, &#x27;num_agent_steps_sampled&#x27;: 76032, &#x27;num_agent_steps_trained&#x27;: 76032}</td><td>{}              </td><td style=\"text-align: right;\">           995.25 </td><td>{}             </td><td style=\"text-align: right;\">                 0  </td><td style=\"text-align: right;\">            -0.623684</td><td style=\"text-align: right;\">               -35.8</td><td style=\"text-align: right;\">                   0</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 0.008572593098506331, &#x27;cur_kl_coeff&#x27;: 1.0660714308858325e-176, &#x27;cur_lr&#x27;: 0.01, &#x27;total_loss&#x27;: 1.1647740999857585e-06, &#x27;policy_loss&#x27;: 7.450580596923828e-08, &#x27;vf_loss&#x27;: 1.2079690066002513e-06, &#x27;vf_explained_var&#x27;: -0.2811831732590993, &#x27;kl&#x27;: 2.1217111088878138e-09, &#x27;entropy&#x27;: 0.00011638018501495632, &#x27;entropy_coeff&#x27;: 0.001}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 64.0, &#x27;num_grad_updates_lifetime&#x27;: 3561.5, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 2.5}}, &#x27;num_env_steps_sampled&#x27;: 76032, &#x27;num_env_steps_trained&#x27;: 76032, &#x27;num_agent_steps_sampled&#x27;: 76032, &#x27;num_agent_steps_trained&#x27;: 76032}                               </td><td style=\"text-align: right;\">                    76032</td><td style=\"text-align: right;\">                    76032</td><td style=\"text-align: right;\">                  76032</td><td style=\"text-align: right;\">                              128</td><td style=\"text-align: right;\">                                   314.643</td><td style=\"text-align: right;\">                  76032</td><td style=\"text-align: right;\">                              128</td><td style=\"text-align: right;\">                                   314.643</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                          128</td><td>{&#x27;cpu_util_percent&#x27;: 70.0, &#x27;ram_util_percent&#x27;: 61.2}                          </td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 0.6258850034340389, &#x27;mean_inference_ms&#x27;: 2.3307488314777203, &#x27;mean_action_processing_ms&#x27;: 0.2405898887139024, &#x27;mean_env_wait_ms&#x27;: 0.1618672582528109, &#x27;mean_env_render_ms&#x27;: 0.0} </td><td>{&#x27;episode_reward_max&#x27;: 0.0, &#x27;episode_reward_min&#x27;: -35.80000000000024, &#x27;episode_reward_mean&#x27;: -0.6236842105263186, &#x27;episode_len_mean&#x27;: 995.25, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 0, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-35.80000000000024, -10.999999999999977, -0.4, 0.0, 0.0, 0.0, 0.0, -0.1, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], &#x27;episode_lengths&#x27;: [836, 729, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.6258850034340389, &#x27;mean_inference_ms&#x27;: 2.3307488314777203, &#x27;mean_action_processing_ms&#x27;: 0.2405898887139024, &#x27;mean_env_wait_ms&#x27;: 0.1618672582528109, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: 0.010656055651212993, &#x27;StateBufferConnector_ms&#x27;: 0.007565084256623921, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.19956262488114207}}                                                                                                                                                                                                                                                                                                                                                                                                                          </td><td>{&#x27;training_iteration_time_ms&#x27;: 420.034, &#x27;sample_time_ms&#x27;: 380.879, &#x27;load_time_ms&#x27;: 0.344, &#x27;load_throughput&#x27;: 372232.484, &#x27;learn_time_ms&#x27;: 38.38, &#x27;learn_throughput&#x27;: 3335.109, &#x27;synch_weights_time_ms&#x27;: 0.005}    </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00004</td><td style=\"text-align: right;\">                    896</td><td>{}                                                                                                                                                             </td><td>{&#x27;num_env_steps_sampled&#x27;: 896, &#x27;num_env_steps_trained&#x27;: 896, &#x27;num_agent_steps_sampled&#x27;: 896, &#x27;num_agent_steps_trained&#x27;: 896}        </td><td>{}              </td><td style=\"text-align: right;\">           nan    </td><td>{}             </td><td style=\"text-align: right;\">               nan  </td><td style=\"text-align: right;\">           nan       </td><td style=\"text-align: right;\">               nan  </td><td style=\"text-align: right;\">                   0</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 4.672012090682983, &#x27;cur_kl_coeff&#x27;: 0.0031249999999999997, &#x27;cur_lr&#x27;: 0.001, &#x27;total_loss&#x27;: 0.5962815284729004, &#x27;policy_loss&#x27;: -0.0017262448867162068, &#x27;vf_loss&#x27;: 0.5990629295508066, &#x27;vf_explained_var&#x27;: -0.4447411000728607, &#x27;kl&#x27;: 0.0001334358884056049, &#x27;entropy&#x27;: 1.0555894772211711, &#x27;entropy_coeff&#x27;: 0.001}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 64.0, &#x27;num_grad_updates_lifetime&#x27;: 39.5, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 2.5}}, &#x27;num_env_steps_sampled&#x27;: 896, &#x27;num_env_steps_trained&#x27;: 896, &#x27;num_agent_steps_sampled&#x27;: 896, &#x27;num_agent_steps_trained&#x27;: 896}                                                         </td><td style=\"text-align: right;\">                      896</td><td style=\"text-align: right;\">                      896</td><td style=\"text-align: right;\">                    896</td><td style=\"text-align: right;\">                              128</td><td style=\"text-align: right;\">                                   198.339</td><td style=\"text-align: right;\">                    896</td><td style=\"text-align: right;\">                              128</td><td style=\"text-align: right;\">                                   198.339</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                          128</td><td>{&#x27;cpu_util_percent&#x27;: 96.1, &#x27;ram_util_percent&#x27;: 62.7}                          </td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{}                                                                                                                                                                                                              </td><td>{&#x27;episode_reward_max&#x27;: nan, &#x27;episode_reward_min&#x27;: nan, &#x27;episode_reward_mean&#x27;: nan, &#x27;episode_len_mean&#x27;: nan, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 0, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [], &#x27;episode_lengths&#x27;: []}, &#x27;sampler_perf&#x27;: {}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </td><td>{&#x27;training_iteration_time_ms&#x27;: 740.05, &#x27;sample_time_ms&#x27;: 672.139, &#x27;load_time_ms&#x27;: 0.512, &#x27;load_throughput&#x27;: 250072.956, &#x27;learn_time_ms&#x27;: 66.867, &#x27;learn_throughput&#x27;: 1914.241, &#x27;synch_weights_time_ms&#x27;: 0.007}    </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00005</td><td style=\"text-align: right;\">                    896</td><td>{}                                                                                                                                                             </td><td>{&#x27;num_env_steps_sampled&#x27;: 896, &#x27;num_env_steps_trained&#x27;: 896, &#x27;num_agent_steps_sampled&#x27;: 896, &#x27;num_agent_steps_trained&#x27;: 896}        </td><td>{}              </td><td style=\"text-align: right;\">           nan    </td><td>{}             </td><td style=\"text-align: right;\">               nan  </td><td style=\"text-align: right;\">           nan       </td><td style=\"text-align: right;\">               nan  </td><td style=\"text-align: right;\">                   0</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 5.266133149464925, &#x27;cur_kl_coeff&#x27;: 0.0031249999999999997, &#x27;cur_lr&#x27;: 0.0005, &#x27;total_loss&#x27;: 0.8538752142339945, &#x27;policy_loss&#x27;: -0.0005280077457427979, &#x27;vf_loss&#x27;: 0.8555006086826324, &#x27;vf_explained_var&#x27;: -0.05987238883972168, &#x27;kl&#x27;: 1.3033004029476084e-05, &#x27;entropy&#x27;: 1.0974429249763489, &#x27;entropy_coeff&#x27;: 0.001}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 64.0, &#x27;num_grad_updates_lifetime&#x27;: 39.5, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 2.5}}, &#x27;num_env_steps_sampled&#x27;: 896, &#x27;num_env_steps_trained&#x27;: 896, &#x27;num_agent_steps_sampled&#x27;: 896, &#x27;num_agent_steps_trained&#x27;: 896}                                                      </td><td style=\"text-align: right;\">                      896</td><td style=\"text-align: right;\">                      896</td><td style=\"text-align: right;\">                    896</td><td style=\"text-align: right;\">                              128</td><td style=\"text-align: right;\">                                   196.08 </td><td style=\"text-align: right;\">                    896</td><td style=\"text-align: right;\">                              128</td><td style=\"text-align: right;\">                                   196.08 </td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                          128</td><td>{&#x27;cpu_util_percent&#x27;: 92.6, &#x27;ram_util_percent&#x27;: 62.5}                          </td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{}                                                                                                                                                                                                              </td><td>{&#x27;episode_reward_max&#x27;: nan, &#x27;episode_reward_min&#x27;: nan, &#x27;episode_reward_mean&#x27;: nan, &#x27;episode_len_mean&#x27;: nan, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 0, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [], &#x27;episode_lengths&#x27;: []}, &#x27;sampler_perf&#x27;: {}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </td><td>{&#x27;training_iteration_time_ms&#x27;: 740.794, &#x27;sample_time_ms&#x27;: 668.507, &#x27;load_time_ms&#x27;: 0.577, &#x27;load_throughput&#x27;: 221808.203, &#x27;learn_time_ms&#x27;: 71.216, &#x27;learn_throughput&#x27;: 1797.356, &#x27;synch_weights_time_ms&#x27;: 0.005}   </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00006</td><td style=\"text-align: right;\">                  82176</td><td>{&#x27;ObsPreprocessorConnector_ms&#x27;: 0.010088511875697545, &#x27;StateBufferConnector_ms&#x27;: 0.0082484313419887, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.30311743418375653}  </td><td>{&#x27;num_env_steps_sampled&#x27;: 82176, &#x27;num_env_steps_trained&#x27;: 82176, &#x27;num_agent_steps_sampled&#x27;: 82176, &#x27;num_agent_steps_trained&#x27;: 82176}</td><td>{}              </td><td style=\"text-align: right;\">           977.583</td><td>{}             </td><td style=\"text-align: right;\">                 0  </td><td style=\"text-align: right;\">            -0.917857</td><td style=\"text-align: right;\">               -40.9</td><td style=\"text-align: right;\">                   1</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 0.04908132137885938, &#x27;cur_kl_coeff&#x27;: 5.393291160605414e-95, &#x27;cur_lr&#x27;: 0.009999999999999998, &#x27;total_loss&#x27;: 5.4677948355674744e-05, &#x27;policy_loss&#x27;: -3.5390257835388184e-08, &#x27;vf_loss&#x27;: 5.477091741094379e-05, &#x27;vf_explained_var&#x27;: -0.4136219322681427, &#x27;kl&#x27;: 1.5024250259180025e-08, &#x27;entropy&#x27;: 6.375279159935114e-05, &#x27;entropy_coeff&#x27;: 0.0010000000000000002}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 64.0, &#x27;num_grad_updates_lifetime&#x27;: 3846.5, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 5.5}}, &#x27;num_env_steps_sampled&#x27;: 82176, &#x27;num_env_steps_trained&#x27;: 82176, &#x27;num_agent_steps_sampled&#x27;: 82176, &#x27;num_agent_steps_trained&#x27;: 82176}  </td><td style=\"text-align: right;\">                    82176</td><td style=\"text-align: right;\">                    82176</td><td style=\"text-align: right;\">                  82176</td><td style=\"text-align: right;\">                              256</td><td style=\"text-align: right;\">                                   316.386</td><td style=\"text-align: right;\">                  82176</td><td style=\"text-align: right;\">                              256</td><td style=\"text-align: right;\">                                   316.386</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                          256</td><td>{&#x27;cpu_util_percent&#x27;: 66.7, &#x27;ram_util_percent&#x27;: 61.2}                          </td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 0.6315373191609022, &#x27;mean_inference_ms&#x27;: 2.3072003199408733, &#x27;mean_action_processing_ms&#x27;: 0.23808655892424865, &#x27;mean_env_wait_ms&#x27;: 0.1623670528249735, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 0.0, &#x27;episode_reward_min&#x27;: -40.90000000000031, &#x27;episode_reward_mean&#x27;: -0.9178571428571457, &#x27;episode_len_mean&#x27;: 977.5833333333334, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 1, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-40.90000000000031, -16.09999999999996, -8.099999999999987, -9.699999999999982, -1.9000000000000006, -0.1, -0.1, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], &#x27;episode_lengths&#x27;: [678, 382, 308, 669, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.6315373191609022, &#x27;mean_inference_ms&#x27;: 2.3072003199408733, &#x27;mean_action_processing_ms&#x27;: 0.23808655892424865, &#x27;mean_env_wait_ms&#x27;: 0.1623670528249735, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: 0.010088511875697545, &#x27;StateBufferConnector_ms&#x27;: 0.0082484313419887, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.30311743418375653}}                                                                                                                                                                                                                                                                            </td><td>{&#x27;training_iteration_time_ms&#x27;: 839.967, &#x27;sample_time_ms&#x27;: 762.626, &#x27;load_time_ms&#x27;: 0.337, &#x27;load_throughput&#x27;: 759257.406, &#x27;learn_time_ms&#x27;: 76.547, &#x27;learn_throughput&#x27;: 3344.371, &#x27;synch_weights_time_ms&#x27;: 0.006}   </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00007</td><td style=\"text-align: right;\">                    768</td><td>{}                                                                                                                                                             </td><td>{&#x27;num_env_steps_sampled&#x27;: 768, &#x27;num_env_steps_trained&#x27;: 768, &#x27;num_agent_steps_sampled&#x27;: 768, &#x27;num_agent_steps_trained&#x27;: 768}        </td><td>{}              </td><td style=\"text-align: right;\">           nan    </td><td>{}             </td><td style=\"text-align: right;\">               nan  </td><td style=\"text-align: right;\">           nan       </td><td style=\"text-align: right;\">               nan  </td><td style=\"text-align: right;\">                   0</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 3.960027813911438, &#x27;cur_kl_coeff&#x27;: 0.10000000000000002, &#x27;cur_lr&#x27;: 0.0010000000000000002, &#x27;total_loss&#x27;: 0.48997879307717085, &#x27;policy_loss&#x27;: -0.011656731367111206, &#x27;vf_loss&#x27;: 0.5025106854736805, &#x27;vf_explained_var&#x27;: -0.553967167933782, &#x27;kl&#x27;: 0.002026959796661787, &#x27;entropy&#x27;: 1.0778366923332214, &#x27;entropy_coeff&#x27;: 0.0010000000000000002}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 64.0, &#x27;num_grad_updates_lifetime&#x27;: 30.5, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 5.5}}, &#x27;num_env_steps_sampled&#x27;: 768, &#x27;num_env_steps_trained&#x27;: 768, &#x27;num_agent_steps_sampled&#x27;: 768, &#x27;num_agent_steps_trained&#x27;: 768}                             </td><td style=\"text-align: right;\">                      768</td><td style=\"text-align: right;\">                      768</td><td style=\"text-align: right;\">                    768</td><td style=\"text-align: right;\">                              256</td><td style=\"text-align: right;\">                                   172.576</td><td style=\"text-align: right;\">                    768</td><td style=\"text-align: right;\">                              256</td><td style=\"text-align: right;\">                                   172.576</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                          256</td><td>{&#x27;cpu_util_percent&#x27;: 60.20000000000001, &#x27;ram_util_percent&#x27;: 62.43333333333334}</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{}                                                                                                                                                                                                              </td><td>{&#x27;episode_reward_max&#x27;: nan, &#x27;episode_reward_min&#x27;: nan, &#x27;episode_reward_mean&#x27;: nan, &#x27;episode_len_mean&#x27;: nan, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 0, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [], &#x27;episode_lengths&#x27;: []}, &#x27;sampler_perf&#x27;: {}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </td><td>{&#x27;training_iteration_time_ms&#x27;: 1537.519, &#x27;sample_time_ms&#x27;: 1392.094, &#x27;load_time_ms&#x27;: 0.848, &#x27;load_throughput&#x27;: 301838.969, &#x27;learn_time_ms&#x27;: 143.679, &#x27;learn_throughput&#x27;: 1781.755, &#x27;synch_weights_time_ms&#x27;: 0.006}</td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00008</td><td style=\"text-align: right;\">                  80640</td><td>{&#x27;ObsPreprocessorConnector_ms&#x27;: 0.010406693746877272, &#x27;StateBufferConnector_ms&#x27;: 0.008349085963049601, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.2492147822712743} </td><td>{&#x27;num_env_steps_sampled&#x27;: 80640, &#x27;num_env_steps_trained&#x27;: 80640, &#x27;num_agent_steps_sampled&#x27;: 80640, &#x27;num_agent_steps_trained&#x27;: 80640}</td><td>{}              </td><td style=\"text-align: right;\">           934.581</td><td>{}             </td><td style=\"text-align: right;\">                 0  </td><td style=\"text-align: right;\">            -3.79535 </td><td style=\"text-align: right;\">               -51.7</td><td style=\"text-align: right;\">                   0</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 0.010140284857091805, &#x27;cur_kl_coeff&#x27;: 5.992545734006015e-96, &#x27;cur_lr&#x27;: 0.0005000000000000001, &#x27;total_loss&#x27;: 3.3366183439890542e-06, &#x27;policy_loss&#x27;: -7.450580596923828e-09, &#x27;vf_loss&#x27;: 3.842990186816071e-06, &#x27;vf_explained_var&#x27;: -0.1874301234881083, &#x27;kl&#x27;: -1.5523401959126788e-09, &#x27;entropy&#x27;: 0.0004924609456793405, &#x27;entropy_coeff&#x27;: 0.0010000000000000002}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 64.0, &#x27;num_grad_updates_lifetime&#x27;: 3774.5, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 5.5}}, &#x27;num_env_steps_sampled&#x27;: 80640, &#x27;num_env_steps_trained&#x27;: 80640, &#x27;num_agent_steps_sampled&#x27;: 80640, &#x27;num_agent_steps_trained&#x27;: 80640}</td><td style=\"text-align: right;\">                    80640</td><td style=\"text-align: right;\">                    80640</td><td style=\"text-align: right;\">                  80640</td><td style=\"text-align: right;\">                              256</td><td style=\"text-align: right;\">                                   323.369</td><td style=\"text-align: right;\">                  80640</td><td style=\"text-align: right;\">                              256</td><td style=\"text-align: right;\">                                   323.369</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                          256</td><td>{&#x27;cpu_util_percent&#x27;: 67.9, &#x27;ram_util_percent&#x27;: 61.2}                          </td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 0.6244109078612382, &#x27;mean_inference_ms&#x27;: 2.364755407445817, &#x27;mean_action_processing_ms&#x27;: 0.25341460831048657, &#x27;mean_env_wait_ms&#x27;: 0.16061883620955733, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 0.0, &#x27;episode_reward_min&#x27;: -51.700000000000465, &#x27;episode_reward_mean&#x27;: -3.7953488372093167, &#x27;episode_len_mean&#x27;: 934.5813953488372, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 0, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-25.200000000000088, -18.799999999999997, -24.200000000000074, -39.30000000000029, -37.50000000000026, -51.700000000000465, -8.499999999999986, -20.200000000000017, -12.89999999999997, -23.10000000000006, -12.099999999999973, -22.100000000000044, -7.19999999999999, -5.999999999999995, -4.5, -2.9000000000000012, -1.2, -1.8000000000000005, -2.2000000000000006, -0.9999999999999999, -0.9999999999999999, -0.5, -0.30000000000000004, -0.1, -0.5, -0.2, 0.0, 0.0, 0.0, -0.1, -0.1, 0.0, -0.1, 0.0, -0.1, 0.0, -0.1, 0.0, -0.1, -0.1, -0.1, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, -0.1, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, -0.1, 0.0, 0.0], &#x27;episode_lengths&#x27;: [379, 298, 399, 603, 638, 1001, 196, 503, 388, 739, 584, 938, 1001, 689, 1001, 1001, 1001, 947, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.6244109078612382, &#x27;mean_inference_ms&#x27;: 2.364755407445817, &#x27;mean_action_processing_ms&#x27;: 0.25341460831048657, &#x27;mean_env_wait_ms&#x27;: 0.16061883620955733, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: 0.010406693746877272, &#x27;StateBufferConnector_ms&#x27;: 0.008349085963049601, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.2492147822712743}}</td><td>{&#x27;training_iteration_time_ms&#x27;: 852.163, &#x27;sample_time_ms&#x27;: 777.142, &#x27;load_time_ms&#x27;: 0.384, &#x27;load_throughput&#x27;: 666878.967, &#x27;learn_time_ms&#x27;: 74.191, &#x27;learn_throughput&#x27;: 3450.568, &#x27;synch_weights_time_ms&#x27;: 0.005}   </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00009</td><td style=\"text-align: right;\">                  84480</td><td>{&#x27;ObsPreprocessorConnector_ms&#x27;: 0.011350820352742961, &#x27;StateBufferConnector_ms&#x27;: 0.00774179186139788, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.20030514224544987} </td><td>{&#x27;num_env_steps_sampled&#x27;: 84480, &#x27;num_env_steps_trained&#x27;: 84480, &#x27;num_agent_steps_sampled&#x27;: 84480, &#x27;num_agent_steps_trained&#x27;: 84480}</td><td>{}              </td><td style=\"text-align: right;\">           928.286</td><td>{}             </td><td style=\"text-align: right;\">                 0  </td><td style=\"text-align: right;\">            -2.44615 </td><td style=\"text-align: right;\">               -57.4</td><td style=\"text-align: right;\">                   1</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 0.027540958079043776, &#x27;cur_kl_coeff&#x27;: 2.660277553366645e-46, &#x27;cur_lr&#x27;: 0.01, &#x27;total_loss&#x27;: 1.607462763786316e-05, &#x27;policy_loss&#x27;: 1.4901161193847656e-08, &#x27;vf_loss&#x27;: 1.615970206358952e-05, &#x27;vf_explained_var&#x27;: 0.08874243994553883, &#x27;kl&#x27;: -1.341079354048406e-09, &#x27;entropy&#x27;: 9.124792601748292e-05, &#x27;entropy_coeff&#x27;: 0.001}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 64.0, &#x27;num_grad_updates_lifetime&#x27;: 3948.5, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 11.5}}, &#x27;num_env_steps_sampled&#x27;: 84480, &#x27;num_env_steps_trained&#x27;: 84480, &#x27;num_agent_steps_sampled&#x27;: 84480, &#x27;num_agent_steps_trained&#x27;: 84480}                                  </td><td style=\"text-align: right;\">                    84480</td><td style=\"text-align: right;\">                    84480</td><td style=\"text-align: right;\">                  84480</td><td style=\"text-align: right;\">                              512</td><td style=\"text-align: right;\">                                   296.515</td><td style=\"text-align: right;\">                  84480</td><td style=\"text-align: right;\">                              512</td><td style=\"text-align: right;\">                                   296.515</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                          512</td><td>{&#x27;cpu_util_percent&#x27;: 70.36666666666667, &#x27;ram_util_percent&#x27;: 61.26666666666667}</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 0.595880801660869, &#x27;mean_inference_ms&#x27;: 2.360611172847669, &#x27;mean_action_processing_ms&#x27;: 0.2426259783235133, &#x27;mean_env_wait_ms&#x27;: 0.16624061665302212, &#x27;mean_env_render_ms&#x27;: 0.0}  </td><td>{&#x27;episode_reward_max&#x27;: 0.0, &#x27;episode_reward_min&#x27;: -57.400000000000546, &#x27;episode_reward_mean&#x27;: -2.4461538461538495, &#x27;episode_len_mean&#x27;: 928.2857142857143, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 1, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-17.59999999999998, -57.400000000000546, -19.60000000000001, -15.89999999999996, -16.499999999999964, -15.69999999999996, -17.999999999999986, -10.399999999999979, -9.699999999999982, -10.699999999999978, -8.999999999999984, -5.599999999999996, -8.099999999999987, -4.799999999999999, -2.3000000000000007, -0.7, -0.2, 0.0, -0.2, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], &#x27;episode_lengths&#x27;: [259, 1001, 399, 342, 460, 502, 554, 381, 401, 409, 700, 626, 572, 791, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.595880801660869, &#x27;mean_inference_ms&#x27;: 2.360611172847669, &#x27;mean_action_processing_ms&#x27;: 0.2426259783235133, &#x27;mean_env_wait_ms&#x27;: 0.16624061665302212, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: 0.011350820352742961, &#x27;StateBufferConnector_ms&#x27;: 0.00774179186139788, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.20030514224544987}}                                            </td><td>{&#x27;training_iteration_time_ms&#x27;: 1690.4, &#x27;sample_time_ms&#x27;: 1537.051, &#x27;load_time_ms&#x27;: 0.437, &#x27;load_throughput&#x27;: 1171631.648, &#x27;learn_time_ms&#x27;: 152.389, &#x27;learn_throughput&#x27;: 3359.821, &#x27;synch_weights_time_ms&#x27;: 0.005} </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00010</td><td style=\"text-align: right;\">                  84480</td><td>{&#x27;ObsPreprocessorConnector_ms&#x27;: 0.011313516040181005, &#x27;StateBufferConnector_ms&#x27;: 0.00825150068416152, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.20280826923459075} </td><td>{&#x27;num_env_steps_sampled&#x27;: 84480, &#x27;num_env_steps_trained&#x27;: 84480, &#x27;num_agent_steps_sampled&#x27;: 84480, &#x27;num_agent_steps_trained&#x27;: 84480}</td><td>{}              </td><td style=\"text-align: right;\">           976.721</td><td>{}             </td><td style=\"text-align: right;\">                 0  </td><td style=\"text-align: right;\">            -1.92674 </td><td style=\"text-align: right;\">               -54.7</td><td style=\"text-align: right;\">                   1</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 0.004243027925743566, &#x27;cur_kl_coeff&#x27;: 1.3684555315672044e-49, &#x27;cur_lr&#x27;: 0.001, &#x27;total_loss&#x27;: -1.9247333208719888e-07, &#x27;policy_loss&#x27;: 1.9868214925130207e-08, &#x27;vf_loss&#x27;: 4.3710549283796735e-07, &#x27;vf_explained_var&#x27;: -0.047054787476857506, &#x27;kl&#x27;: 1.9466292970328437e-10, &#x27;entropy&#x27;: 0.0006441557391857108, &#x27;entropy_coeff&#x27;: 0.001}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 64.0, &#x27;num_grad_updates_lifetime&#x27;: 3948.5, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 11.5}}, &#x27;num_env_steps_sampled&#x27;: 84480, &#x27;num_env_steps_trained&#x27;: 84480, &#x27;num_agent_steps_sampled&#x27;: 84480, &#x27;num_agent_steps_trained&#x27;: 84480}                           </td><td style=\"text-align: right;\">                    84480</td><td style=\"text-align: right;\">                    84480</td><td style=\"text-align: right;\">                  84480</td><td style=\"text-align: right;\">                              512</td><td style=\"text-align: right;\">                                   300.134</td><td style=\"text-align: right;\">                  84480</td><td style=\"text-align: right;\">                              512</td><td style=\"text-align: right;\">                                   300.134</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                          512</td><td>{&#x27;cpu_util_percent&#x27;: 46.6, &#x27;ram_util_percent&#x27;: 61.26666666666667}             </td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 0.5925572172614968, &#x27;mean_inference_ms&#x27;: 2.3438906644540185, &#x27;mean_action_processing_ms&#x27;: 0.2539730126980808, &#x27;mean_env_wait_ms&#x27;: 0.16267179205828597, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 0.0, &#x27;episode_reward_min&#x27;: -54.70000000000051, &#x27;episode_reward_mean&#x27;: -1.92674418604652, &#x27;episode_len_mean&#x27;: 976.7209302325581, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 1, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-20.40000000000002, -19.300000000000004, -54.70000000000051, -22.40000000000005, -30.20000000000016, -9.399999999999983, -3.900000000000002, -1.8000000000000005, -0.9999999999999999, -0.5, -1.0999999999999999, -0.1, -0.2, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], &#x27;episode_lengths&#x27;: [285, 309, 1001, 475, 847, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.5925572172614968, &#x27;mean_inference_ms&#x27;: 2.3438906644540185, &#x27;mean_action_processing_ms&#x27;: 0.2539730126980808, &#x27;mean_env_wait_ms&#x27;: 0.16267179205828597, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: 0.011313516040181005, &#x27;StateBufferConnector_ms&#x27;: 0.00825150068416152, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.20280826923459075}}                                                                                                                                                                      </td><td>{&#x27;training_iteration_time_ms&#x27;: 1711.152, &#x27;sample_time_ms&#x27;: 1563.161, &#x27;load_time_ms&#x27;: 0.418, &#x27;load_throughput&#x27;: 1226012.587, &#x27;learn_time_ms&#x27;: 147.12, &#x27;learn_throughput&#x27;: 3480.16, &#x27;synch_weights_time_ms&#x27;: 0.005} </td></tr>\n",
       "<tr><td>PPO_cartpole_swingup_1_d3aa5_00011</td><td style=\"text-align: right;\">                   1024</td><td>{&#x27;ObsPreprocessorConnector_ms&#x27;: 0.012862682342529297, &#x27;StateBufferConnector_ms&#x27;: 0.00985860824584961, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.2619504928588867}  </td><td>{&#x27;num_env_steps_sampled&#x27;: 1024, &#x27;num_env_steps_trained&#x27;: 1024, &#x27;num_agent_steps_sampled&#x27;: 1024, &#x27;num_agent_steps_trained&#x27;: 1024}    </td><td>{}              </td><td style=\"text-align: right;\">           387    </td><td>{}             </td><td style=\"text-align: right;\">               -24.8</td><td style=\"text-align: right;\">           -25.15    </td><td style=\"text-align: right;\">               -25.5</td><td style=\"text-align: right;\">                   1</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 3.9953919450441995, &#x27;cur_kl_coeff&#x27;: 0.10000000000000002, &#x27;cur_lr&#x27;: 0.0005, &#x27;total_loss&#x27;: 0.5192205410761138, &#x27;policy_loss&#x27;: -0.007994502938042084, &#x27;vf_loss&#x27;: 0.5282114930450916, &#x27;vf_explained_var&#x27;: -0.016719341278076172, &#x27;kl&#x27;: 0.0009595869848334956, &#x27;entropy&#x27;: 1.0924206028381984, &#x27;entropy_coeff&#x27;: 0.001}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 64.0, &#x27;num_grad_updates_lifetime&#x27;: 36.5, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 11.5}}, &#x27;num_env_steps_sampled&#x27;: 1024, &#x27;num_env_steps_trained&#x27;: 1024, &#x27;num_agent_steps_sampled&#x27;: 1024, &#x27;num_agent_steps_trained&#x27;: 1024}                                                   </td><td style=\"text-align: right;\">                     1024</td><td style=\"text-align: right;\">                     1024</td><td style=\"text-align: right;\">                   1024</td><td style=\"text-align: right;\">                              512</td><td style=\"text-align: right;\">                                   172.981</td><td style=\"text-align: right;\">                   1024</td><td style=\"text-align: right;\">                              512</td><td style=\"text-align: right;\">                                   172.981</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                          512</td><td>{&#x27;cpu_util_percent&#x27;: 47.474999999999994, &#x27;ram_util_percent&#x27;: 62.5}            </td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 0.8682827948843799, &#x27;mean_inference_ms&#x27;: 3.805379168382981, &#x27;mean_action_processing_ms&#x27;: 0.4554470471964466, &#x27;mean_env_wait_ms&#x27;: 0.25697395928841327, &#x27;mean_env_render_ms&#x27;: 0.0} </td><td>{&#x27;episode_reward_max&#x27;: -24.800000000000082, &#x27;episode_reward_min&#x27;: -25.500000000000092, &#x27;episode_reward_mean&#x27;: -25.150000000000087, &#x27;episode_len_mean&#x27;: 387.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 1, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-25.500000000000092, -24.800000000000082], &#x27;episode_lengths&#x27;: [382, 392]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.8682827948843799, &#x27;mean_inference_ms&#x27;: 3.805379168382981, &#x27;mean_action_processing_ms&#x27;: 0.4554470471964466, &#x27;mean_env_wait_ms&#x27;: 0.25697395928841327, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: 0.012862682342529297, &#x27;StateBufferConnector_ms&#x27;: 0.00985860824584961, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.2619504928588867}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td><td>{&#x27;training_iteration_time_ms&#x27;: 3031.005, &#x27;sample_time_ms&#x27;: 2732.929, &#x27;load_time_ms&#x27;: 0.471, &#x27;load_throughput&#x27;: 1087884.32, &#x27;learn_time_ms&#x27;: 297.024, &#x27;learn_throughput&#x27;: 1723.769, &#x27;synch_weights_time_ms&#x27;: 0.007}</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 13:44:54,174\tERROR tune_controller.py:873 -- Trial task failed for trial PPO_cartpole_swingup_1_d3aa5_00007\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::PPO.train()\u001b[39m (pid=95636, ip=127.0.0.1, actor_id=5a8bbc6fd04d5b247275c10001000000, repr=PPO)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py\", line 803, in step\n",
      "    results, train_iter_ctx = self._run_one_training_iteration()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py\", line 2853, in _run_one_training_iteration\n",
      "    results = self.training_step()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/algorithms/ppo/ppo.py\", line 403, in training_step\n",
      "    train_batch = synchronous_parallel_sample(\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/execution/rollout_ops.py\", line 82, in synchronous_parallel_sample\n",
      "    sample_batches = [worker_set.local_worker().sample()]\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 915, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 277, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 323, in run\n",
      "    outputs = self.step()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 379, in step\n",
      "    self._base_env.send_actions(actions_to_send)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 464, in send_actions\n",
      "    ) = self.vector_env.vector_step(action_vector)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 360, in vector_step\n",
      "    raise e\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 353, in vector_step\n",
      "    results = self.envs[i].step(actions[i])\n",
      "  File \"/Users/adamprice/RLOlympics/rllib_wrapper.py\", line 47, in step\n",
      "    timestep = self._env.step(action)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/utils/wrappers.py\", line 76, in step\n",
      "    self._track(timestep)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/utils/wrappers.py\", line 102, in _track\n",
      "    self._log_bsuite_data()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/utils/wrappers.py\", line 125, in _log_bsuite_data\n",
      "    self._logger.write(data)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/logging/sqlite_logging.py\", line 102, in write\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Caught SQL integrity error. This is probably caused by attempting to overwrite existing rows in table \"cartpole_swingup\" in database at /Users/adamprice/RLOlympics/results/PPO/data.db. You may want to specify a different database file.\n",
      "2023-07-18 13:44:54,341\tERROR tune_controller.py:873 -- Trial task failed for trial PPO_cartpole_swingup_1_d3aa5_00005\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::PPO.train()\u001b[39m (pid=95634, ip=127.0.0.1, actor_id=1c0b1256e60d12b8b5d269b801000000, repr=PPO)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py\", line 803, in step\n",
      "    results, train_iter_ctx = self._run_one_training_iteration()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py\", line 2853, in _run_one_training_iteration\n",
      "    results = self.training_step()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/algorithms/ppo/ppo.py\", line 403, in training_step\n",
      "    train_batch = synchronous_parallel_sample(\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/execution/rollout_ops.py\", line 82, in synchronous_parallel_sample\n",
      "    sample_batches = [worker_set.local_worker().sample()]\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 915, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 277, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 323, in run\n",
      "    outputs = self.step()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 379, in step\n",
      "    self._base_env.send_actions(actions_to_send)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 464, in send_actions\n",
      "    ) = self.vector_env.vector_step(action_vector)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 360, in vector_step\n",
      "    raise e\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 353, in vector_step\n",
      "    results = self.envs[i].step(actions[i])\n",
      "  File \"/Users/adamprice/RLOlympics/rllib_wrapper.py\", line 47, in step\n",
      "    timestep = self._env.step(action)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/utils/wrappers.py\", line 76, in step\n",
      "    self._track(timestep)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/utils/wrappers.py\", line 102, in _track\n",
      "    self._log_bsuite_data()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/utils/wrappers.py\", line 125, in _log_bsuite_data\n",
      "    self._logger.write(data)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/logging/sqlite_logging.py\", line 102, in write\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Caught SQL integrity error. This is probably caused by attempting to overwrite existing rows in table \"cartpole_swingup\" in database at /Users/adamprice/RLOlympics/results/PPO/data.db. You may want to specify a different database file.\n",
      "2023-07-18 13:44:54,477\tERROR tune_controller.py:873 -- Trial task failed for trial PPO_cartpole_swingup_1_d3aa5_00004\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::PPO.train()\u001b[39m (pid=95633, ip=127.0.0.1, actor_id=3c30d9c578b709d1ecc6ab9f01000000, repr=PPO)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py\", line 803, in step\n",
      "    results, train_iter_ctx = self._run_one_training_iteration()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py\", line 2853, in _run_one_training_iteration\n",
      "    results = self.training_step()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/algorithms/ppo/ppo.py\", line 403, in training_step\n",
      "    train_batch = synchronous_parallel_sample(\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/execution/rollout_ops.py\", line 82, in synchronous_parallel_sample\n",
      "    sample_batches = [worker_set.local_worker().sample()]\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 915, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 277, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 323, in run\n",
      "    outputs = self.step()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 379, in step\n",
      "    self._base_env.send_actions(actions_to_send)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 464, in send_actions\n",
      "    ) = self.vector_env.vector_step(action_vector)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 360, in vector_step\n",
      "    raise e\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 353, in vector_step\n",
      "    results = self.envs[i].step(actions[i])\n",
      "  File \"/Users/adamprice/RLOlympics/rllib_wrapper.py\", line 47, in step\n",
      "    timestep = self._env.step(action)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/utils/wrappers.py\", line 76, in step\n",
      "    self._track(timestep)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/utils/wrappers.py\", line 102, in _track\n",
      "    self._log_bsuite_data()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/utils/wrappers.py\", line 125, in _log_bsuite_data\n",
      "    self._logger.write(data)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/logging/sqlite_logging.py\", line 102, in write\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Caught SQL integrity error. This is probably caused by attempting to overwrite existing rows in table \"cartpole_swingup\" in database at /Users/adamprice/RLOlympics/results/PPO/data.db. You may want to specify a different database file.\n",
      "2023-07-18 13:44:55,426\tERROR tune_controller.py:873 -- Trial task failed for trial PPO_cartpole_swingup_1_d3aa5_00011\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::PPO.train()\u001b[39m (pid=95640, ip=127.0.0.1, actor_id=3246b9096b5167ee02a9b91401000000, repr=PPO)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py\", line 803, in step\n",
      "    results, train_iter_ctx = self._run_one_training_iteration()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py\", line 2853, in _run_one_training_iteration\n",
      "    results = self.training_step()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/algorithms/ppo/ppo.py\", line 403, in training_step\n",
      "    train_batch = synchronous_parallel_sample(\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/execution/rollout_ops.py\", line 82, in synchronous_parallel_sample\n",
      "    sample_batches = [worker_set.local_worker().sample()]\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 915, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 277, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 323, in run\n",
      "    outputs = self.step()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 379, in step\n",
      "    self._base_env.send_actions(actions_to_send)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 464, in send_actions\n",
      "    ) = self.vector_env.vector_step(action_vector)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 360, in vector_step\n",
      "    raise e\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 353, in vector_step\n",
      "    results = self.envs[i].step(actions[i])\n",
      "  File \"/Users/adamprice/RLOlympics/rllib_wrapper.py\", line 47, in step\n",
      "    timestep = self._env.step(action)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/utils/wrappers.py\", line 76, in step\n",
      "    self._track(timestep)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/utils/wrappers.py\", line 102, in _track\n",
      "    self._log_bsuite_data()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/utils/wrappers.py\", line 125, in _log_bsuite_data\n",
      "    self._logger.write(data)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/logging/sqlite_logging.py\", line 102, in write\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Caught SQL integrity error. This is probably caused by attempting to overwrite existing rows in table \"cartpole_swingup\" in database at /Users/adamprice/RLOlympics/results/PPO/data.db. You may want to specify a different database file.\n",
      "2023-07-18 13:45:08,955\tERROR tune_controller.py:873 -- Trial task failed for trial PPO_cartpole_swingup_1_d3aa5_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::PPO.train()\u001b[39m (pid=95629, ip=127.0.0.1, actor_id=b996868270b2486e92fe85b401000000, repr=PPO)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 386, in train\n",
      "    result = self.step()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py\", line 803, in step\n",
      "    results, train_iter_ctx = self._run_one_training_iteration()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py\", line 2853, in _run_one_training_iteration\n",
      "    results = self.training_step()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/algorithms/ppo/ppo.py\", line 403, in training_step\n",
      "    train_batch = synchronous_parallel_sample(\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/execution/rollout_ops.py\", line 82, in synchronous_parallel_sample\n",
      "    sample_batches = [worker_set.local_worker().sample()]\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 915, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 277, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 323, in run\n",
      "    outputs = self.step()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 379, in step\n",
      "    self._base_env.send_actions(actions_to_send)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 464, in send_actions\n",
      "    ) = self.vector_env.vector_step(action_vector)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 360, in vector_step\n",
      "    raise e\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 353, in vector_step\n",
      "    results = self.envs[i].step(actions[i])\n",
      "  File \"/Users/adamprice/RLOlympics/rllib_wrapper.py\", line 47, in step\n",
      "    timestep = self._env.step(action)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/utils/wrappers.py\", line 76, in step\n",
      "    self._track(timestep)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/utils/wrappers.py\", line 102, in _track\n",
      "    self._log_bsuite_data()\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/utils/wrappers.py\", line 125, in _log_bsuite_data\n",
      "    self._logger.write(data)\n",
      "  File \"/Users/adamprice/Applications/anaconda3/envs/rlolympics/lib/python3.9/site-packages/bsuite/logging/sqlite_logging.py\", line 102, in write\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Caught SQL integrity error. This is probably caused by attempting to overwrite existing rows in table \"cartpole_swingup\" in database at /Users/adamprice/RLOlympics/results/PPO/data.db. You may want to specify a different database file.\n",
      "2023-07-18 13:49:58,610\tWARNING tune.py:192 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2023-07-18 13:50:00,002\tERROR tune.py:1107 -- Trials did not complete: [PPO_cartpole_swingup_1_d3aa5_00000, PPO_cartpole_swingup_1_d3aa5_00004, PPO_cartpole_swingup_1_d3aa5_00005, PPO_cartpole_swingup_1_d3aa5_00007, PPO_cartpole_swingup_1_d3aa5_00011]\n",
      "2023-07-18 13:50:00,004\tINFO tune.py:1111 -- Total run time: 334.70 seconds (333.34 seconds for the tuning loop).\n",
      "2023-07-18 13:50:00,005\tWARNING tune.py:1126 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/Users/adamprice/ray_results/PPO\", trainable=...)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResultGrid<[\n",
       "  Result(\n",
       "    error='RayTaskError(RuntimeError)',\n",
       "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.11014328710734844, 'cur_kl_coeff': 1.1102230246251568e-17, 'cur_lr': 0.01, 'total_loss': 0.00020812731236219406, 'policy_loss': 2.146698534488678e-06, 'vf_loss': 0.00020641650462494, 'vf_explained_var': -0.7508742809295654, 'kl': 8.762519196163036e-07, 'entropy': 0.0004409714504921188, 'entropy_coeff': 0.001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 179.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0}}, 'num_env_steps_sampled': 3840, 'num_env_steps_trained': 3840, 'num_agent_steps_sampled': 3840, 'num_agent_steps_trained': 3840}, 'sampler_results': {'episode_reward_max': 0.0, 'episode_reward_min': -17.299999999999976, 'episode_reward_mean': -5.449999999999995, 'episode_len_mean': 482.8333333333333, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-17.299999999999976, -7.19999999999999, -3.800000000000002, -3.1000000000000014, -1.3, 0.0], 'episode_lengths': [262, 179, 177, 277, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9661069735963624, 'mean_inference_ms': 3.2034059297329525, 'mean_action_processing_ms': 0.309174309476905, 'mean_env_wait_ms': 0.25387105184804076, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.016121069590250652, 'StateBufferConnector_ms': 0.009250640869140625, 'ViewRequirementAgentConnector_ms': 0.24902423222859701}}, 'episode_reward_max': 0.0, 'episode_reward_min': -17.299999999999976, 'episode_reward_mean': -5.449999999999995, 'episode_len_mean': 482.8333333333333, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-17.299999999999976, -7.19999999999999, -3.800000000000002, -3.1000000000000014, -1.3, 0.0], 'episode_lengths': [262, 179, 177, 277, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9661069735963624, 'mean_inference_ms': 3.2034059297329525, 'mean_action_processing_ms': 0.309174309476905, 'mean_env_wait_ms': 0.25387105184804076, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.016121069590250652, 'StateBufferConnector_ms': 0.009250640869140625, 'ViewRequirementAgentConnector_ms': 0.24902423222859701}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 3840, 'num_agent_steps_trained': 3840, 'num_env_steps_sampled': 3840, 'num_env_steps_trained': 3840, 'num_env_steps_sampled_this_iter': 64, 'num_env_steps_trained_this_iter': 64, 'num_env_steps_sampled_throughput_per_sec': 182.3263618333469, 'num_env_steps_trained_throughput_per_sec': 182.3263618333469, 'num_steps_trained_this_iter': 64, 'agent_timesteps_total': 3840, 'timers': {'training_iteration_time_ms': 245.463, 'sample_time_ms': 223.605, 'load_time_ms': 0.399, 'load_throughput': 160365.288, 'learn_time_ms': 21.04, 'learn_throughput': 3041.762, 'synch_weights_time_ms': 0.005}, 'counters': {'num_env_steps_sampled': 3840, 'num_env_steps_trained': 3840, 'num_agent_steps_sampled': 3840, 'num_agent_steps_trained': 3840}, 'done': False, 'trial_id': 'd3aa5_00000', 'perf': {'cpu_util_percent': 73.9, 'ram_util_percent': 56.8}, 'experiment_tag': '0_lr=0.0100,train_batch_size=64'},\n",
       "    path='/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00000_0_lr=0.0100,train_batch_size=64_2023-07-18_13-44-25',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.0028165880357846618, 'cur_kl_coeff': 0.0, 'cur_lr': 0.001, 'total_loss': -3.0857821305592853e-07, 'policy_loss': 1.1920928955078125e-07, 'vf_loss': 1.8278087310363844e-07, 'vf_explained_var': 0.9583510955174764, 'kl': 6.4238444656232e-10, 'entropy': 0.0006013214200114211, 'entropy_coeff': 0.001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 3242.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0}}, 'num_env_steps_sampled': 69184, 'num_env_steps_trained': 69184, 'num_agent_steps_sampled': 69184, 'num_agent_steps_trained': 69184}, 'sampler_results': {'episode_reward_max': 0.0, 'episode_reward_min': -57.70000000000055, 'episode_reward_mean': -2.5457142857143014, 'episode_len_mean': 982.9714285714285, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-57.70000000000055, -22.700000000000053, -27.200000000000117, -39.40000000000039, -18.39999999999999, -4.999999999999998, -3.800000000000002, -0.7999999999999999, -0.2, -0.5, -0.2, -0.6, -0.7, 0.0, -0.1, 0.0, -0.2, 0.0, 0.0, 0.0, -0.1, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [963, 369, 492, 1001, 918, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.6752244636764079, 'mean_inference_ms': 2.315578591215869, 'mean_action_processing_ms': 0.23719647150313194, 'mean_env_wait_ms': 0.16014791669360773, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.010329314640590124, 'StateBufferConnector_ms': 0.007821151188441686, 'ViewRequirementAgentConnector_ms': 0.20341941288539342}}, 'episode_reward_max': 0.0, 'episode_reward_min': -57.70000000000055, 'episode_reward_mean': -2.5457142857143014, 'episode_len_mean': 982.9714285714285, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-57.70000000000055, -22.700000000000053, -27.200000000000117, -39.40000000000039, -18.39999999999999, -4.999999999999998, -3.800000000000002, -0.7999999999999999, -0.2, -0.5, -0.2, -0.6, -0.7, 0.0, -0.1, 0.0, -0.2, 0.0, 0.0, 0.0, -0.1, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [963, 369, 492, 1001, 918, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.6752244636764079, 'mean_inference_ms': 2.315578591215869, 'mean_action_processing_ms': 0.23719647150313194, 'mean_env_wait_ms': 0.16014791669360773, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.010329314640590124, 'StateBufferConnector_ms': 0.007821151188441686, 'ViewRequirementAgentConnector_ms': 0.20341941288539342}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 69184, 'num_agent_steps_trained': 69184, 'num_env_steps_sampled': 69184, 'num_env_steps_trained': 69184, 'num_env_steps_sampled_this_iter': 64, 'num_env_steps_trained_this_iter': 64, 'num_env_steps_sampled_throughput_per_sec': 286.331763907763, 'num_env_steps_trained_throughput_per_sec': 286.331763907763, 'num_steps_trained_this_iter': 64, 'agent_timesteps_total': 69184, 'timers': {'training_iteration_time_ms': 238.809, 'sample_time_ms': 217.24, 'load_time_ms': 0.367, 'load_throughput': 174558.106, 'learn_time_ms': 20.76, 'learn_throughput': 3082.822, 'synch_weights_time_ms': 0.009}, 'counters': {'num_env_steps_sampled': 69184, 'num_env_steps_trained': 69184, 'num_agent_steps_sampled': 69184, 'num_agent_steps_trained': 69184}, 'done': False, 'trial_id': 'd3aa5_00001', 'perf': {'cpu_util_percent': 80.7, 'ram_util_percent': 61.2}, 'experiment_tag': '1_lr=0.0010,train_batch_size=64'},\n",
       "    path='/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00001_1_lr=0.0010,train_batch_size=64_2023-07-18_13-44-25',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.003576418695350488, 'cur_kl_coeff': 0.0, 'cur_lr': 0.0005, 'total_loss': -8.940696716308594e-07, 'policy_loss': -1.862645149230957e-07, 'vf_loss': 1.5192498636906748e-07, 'vf_explained_var': 0.9742724299430847, 'kl': 4.356249707025232e-09, 'entropy': 0.0008609466021880507, 'entropy_coeff': 0.001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 3251.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0}}, 'num_env_steps_sampled': 69376, 'num_env_steps_trained': 69376, 'num_agent_steps_sampled': 69376, 'num_agent_steps_trained': 69376}, 'sampler_results': {'episode_reward_max': 0.0, 'episode_reward_min': -49.30000000000043, 'episode_reward_mean': -4.439726027397282, 'episode_len_mean': 938.4931506849315, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-48.10000000000041, -49.30000000000043, -14.599999999999964, -35.70000000000024, -31.30000000000036, -35.600000000000236, -18.099999999999987, -26.70000000000011, -13.799999999999967, -14.099999999999966, -13.199999999999969, -6.5999999999999925, -3.3000000000000016, -3.0000000000000013, -3.0000000000000013, -0.5, -0.7, -2.800000000000001, -0.4, -0.1, -0.4, -0.30000000000000004, -0.1, -0.2, -0.30000000000000004, -0.2, 0.0, -0.1, -0.30000000000000004, 0.0, -0.1, -0.1, 0.0, -0.1, 0.0, -0.1, -0.1, 0.0, -0.2, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [702, 754, 261, 564, 697, 636, 388, 657, 456, 657, 1001, 1001, 676, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.6796448304255731, 'mean_inference_ms': 2.344889904310126, 'mean_action_processing_ms': 0.23958378092873528, 'mean_env_wait_ms': 0.15943557993729296, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.010189618149848834, 'StateBufferConnector_ms': 0.0088796223679634, 'ViewRequirementAgentConnector_ms': 0.19079005881531597}}, 'episode_reward_max': 0.0, 'episode_reward_min': -49.30000000000043, 'episode_reward_mean': -4.439726027397282, 'episode_len_mean': 938.4931506849315, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-48.10000000000041, -49.30000000000043, -14.599999999999964, -35.70000000000024, -31.30000000000036, -35.600000000000236, -18.099999999999987, -26.70000000000011, -13.799999999999967, -14.099999999999966, -13.199999999999969, -6.5999999999999925, -3.3000000000000016, -3.0000000000000013, -3.0000000000000013, -0.5, -0.7, -2.800000000000001, -0.4, -0.1, -0.4, -0.30000000000000004, -0.1, -0.2, -0.30000000000000004, -0.2, 0.0, -0.1, -0.30000000000000004, 0.0, -0.1, -0.1, 0.0, -0.1, 0.0, -0.1, -0.1, 0.0, -0.2, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [702, 754, 261, 564, 697, 636, 388, 657, 456, 657, 1001, 1001, 676, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.6796448304255731, 'mean_inference_ms': 2.344889904310126, 'mean_action_processing_ms': 0.23958378092873528, 'mean_env_wait_ms': 0.15943557993729296, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.010189618149848834, 'StateBufferConnector_ms': 0.0088796223679634, 'ViewRequirementAgentConnector_ms': 0.19079005881531597}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 69376, 'num_agent_steps_trained': 69376, 'num_env_steps_sampled': 69376, 'num_env_steps_trained': 69376, 'num_env_steps_sampled_this_iter': 64, 'num_env_steps_trained_this_iter': 64, 'num_env_steps_sampled_throughput_per_sec': 330.68979382662513, 'num_env_steps_trained_throughput_per_sec': 330.68979382662513, 'num_steps_trained_this_iter': 64, 'agent_timesteps_total': 69376, 'timers': {'training_iteration_time_ms': 247.486, 'sample_time_ms': 224.299, 'load_time_ms': 0.38, 'load_throughput': 168572.881, 'learn_time_ms': 22.23, 'learn_throughput': 2878.992, 'synch_weights_time_ms': 0.006}, 'counters': {'num_env_steps_sampled': 69376, 'num_env_steps_trained': 69376, 'num_agent_steps_sampled': 69376, 'num_agent_steps_trained': 69376}, 'done': False, 'trial_id': 'd3aa5_00002', 'perf': {}, 'experiment_tag': '2_lr=0.0005,train_batch_size=64'},\n",
       "    path='/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00002_2_lr=0.0005,train_batch_size=64_2023-07-18_13-44-25',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.015871344367042184, 'cur_kl_coeff': 6.662946443036453e-178, 'cur_lr': 0.01, 'total_loss': 3.923972447713216e-06, 'policy_loss': -1.4901161193847656e-07, 'vf_loss': 4.120180032411251e-06, 'vf_explained_var': -0.010828624169031778, 'kl': -1.5319695587332853e-09, 'entropy': 7.1351900260197e-05, 'entropy_coeff': 0.001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 3585.5, 'diff_num_grad_updates_vs_sampler_policy': 2.5}}, 'num_env_steps_sampled': 76544, 'num_env_steps_trained': 76544, 'num_agent_steps_sampled': 76544, 'num_agent_steps_trained': 76544}, 'sampler_results': {'episode_reward_max': 0.0, 'episode_reward_min': -35.80000000000024, 'episode_reward_mean': -0.6236842105263186, 'episode_len_mean': 995.25, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-35.80000000000024, -10.999999999999977, -0.4, 0.0, 0.0, 0.0, 0.0, -0.1, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [836, 729, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.6258850034340389, 'mean_inference_ms': 2.3307488314777203, 'mean_action_processing_ms': 0.2405898887139024, 'mean_env_wait_ms': 0.1618672582528109, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.010656055651212993, 'StateBufferConnector_ms': 0.007565084256623921, 'ViewRequirementAgentConnector_ms': 0.19956262488114207}}, 'episode_reward_max': 0.0, 'episode_reward_min': -35.80000000000024, 'episode_reward_mean': -0.6236842105263186, 'episode_len_mean': 995.25, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-35.80000000000024, -10.999999999999977, -0.4, 0.0, 0.0, 0.0, 0.0, -0.1, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [836, 729, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.6258850034340389, 'mean_inference_ms': 2.3307488314777203, 'mean_action_processing_ms': 0.2405898887139024, 'mean_env_wait_ms': 0.1618672582528109, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.010656055651212993, 'StateBufferConnector_ms': 0.007565084256623921, 'ViewRequirementAgentConnector_ms': 0.19956262488114207}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 76544, 'num_agent_steps_trained': 76544, 'num_env_steps_sampled': 76544, 'num_env_steps_trained': 76544, 'num_env_steps_sampled_this_iter': 128, 'num_env_steps_trained_this_iter': 128, 'num_env_steps_sampled_throughput_per_sec': 181.85544334111853, 'num_env_steps_trained_throughput_per_sec': 181.85544334111853, 'num_steps_trained_this_iter': 128, 'agent_timesteps_total': 76544, 'timers': {'training_iteration_time_ms': 460.676, 'sample_time_ms': 416.58, 'load_time_ms': 0.385, 'load_throughput': 332736.853, 'learn_time_ms': 43.194, 'learn_throughput': 2963.379, 'synch_weights_time_ms': 0.005}, 'counters': {'num_env_steps_sampled': 76544, 'num_env_steps_trained': 76544, 'num_agent_steps_sampled': 76544, 'num_agent_steps_trained': 76544}, 'done': False, 'trial_id': 'd3aa5_00003', 'perf': {'cpu_util_percent': 80.4, 'ram_util_percent': 61.2}, 'experiment_tag': '3_lr=0.0100,train_batch_size=128'},\n",
       "    path='/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00003_3_lr=0.0100,train_batch_size=128_2023-07-18_13-44-25',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    error='RayTaskError(RuntimeError)',\n",
       "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.672012090682983, 'cur_kl_coeff': 0.0031249999999999997, 'cur_lr': 0.001, 'total_loss': 0.5962815284729004, 'policy_loss': -0.0017262448867162068, 'vf_loss': 0.5990629295508066, 'vf_explained_var': -0.4447411000728607, 'kl': 0.0001334358884056049, 'entropy': 1.0555894772211711, 'entropy_coeff': 0.001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 39.5, 'diff_num_grad_updates_vs_sampler_policy': 2.5}}, 'num_env_steps_sampled': 896, 'num_env_steps_trained': 896, 'num_agent_steps_sampled': 896, 'num_agent_steps_trained': 896}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 896, 'num_agent_steps_trained': 896, 'num_env_steps_sampled': 896, 'num_env_steps_trained': 896, 'num_env_steps_sampled_this_iter': 128, 'num_env_steps_trained_this_iter': 128, 'num_env_steps_sampled_throughput_per_sec': 198.33913359265236, 'num_env_steps_trained_throughput_per_sec': 198.33913359265236, 'num_steps_trained_this_iter': 128, 'agent_timesteps_total': 896, 'timers': {'training_iteration_time_ms': 740.05, 'sample_time_ms': 672.139, 'load_time_ms': 0.512, 'load_throughput': 250072.956, 'learn_time_ms': 66.867, 'learn_throughput': 1914.241, 'synch_weights_time_ms': 0.007}, 'counters': {'num_env_steps_sampled': 896, 'num_env_steps_trained': 896, 'num_agent_steps_sampled': 896, 'num_agent_steps_trained': 896}, 'done': False, 'trial_id': 'd3aa5_00004', 'perf': {'cpu_util_percent': 96.1, 'ram_util_percent': 62.7}, 'experiment_tag': '4_lr=0.0010,train_batch_size=128'},\n",
       "    path='/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00004_4_lr=0.0010,train_batch_size=128_2023-07-18_13-44-25',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    error='RayTaskError(RuntimeError)',\n",
       "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 5.266133149464925, 'cur_kl_coeff': 0.0031249999999999997, 'cur_lr': 0.0005, 'total_loss': 0.8538752142339945, 'policy_loss': -0.0005280077457427979, 'vf_loss': 0.8555006086826324, 'vf_explained_var': -0.05987238883972168, 'kl': 1.3033004029476084e-05, 'entropy': 1.0974429249763489, 'entropy_coeff': 0.001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 39.5, 'diff_num_grad_updates_vs_sampler_policy': 2.5}}, 'num_env_steps_sampled': 896, 'num_env_steps_trained': 896, 'num_agent_steps_sampled': 896, 'num_agent_steps_trained': 896}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 896, 'num_agent_steps_trained': 896, 'num_env_steps_sampled': 896, 'num_env_steps_trained': 896, 'num_env_steps_sampled_this_iter': 128, 'num_env_steps_trained_this_iter': 128, 'num_env_steps_sampled_throughput_per_sec': 196.08048318251227, 'num_env_steps_trained_throughput_per_sec': 196.08048318251227, 'num_steps_trained_this_iter': 128, 'agent_timesteps_total': 896, 'timers': {'training_iteration_time_ms': 740.794, 'sample_time_ms': 668.507, 'load_time_ms': 0.577, 'load_throughput': 221808.203, 'learn_time_ms': 71.216, 'learn_throughput': 1797.356, 'synch_weights_time_ms': 0.005}, 'counters': {'num_env_steps_sampled': 896, 'num_env_steps_trained': 896, 'num_agent_steps_sampled': 896, 'num_agent_steps_trained': 896}, 'done': False, 'trial_id': 'd3aa5_00005', 'perf': {'cpu_util_percent': 92.6, 'ram_util_percent': 62.5}, 'experiment_tag': '5_lr=0.0005,train_batch_size=128'},\n",
       "    path='/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00005_5_lr=0.0005,train_batch_size=128_2023-07-18_13-44-25',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.04395263790259681, 'cur_kl_coeff': 2.696645580302707e-95, 'cur_lr': 0.009999999999999998, 'total_loss': 4.186232884724935e-05, 'policy_loss': -3.129243850708008e-07, 'vf_loss': 4.225338344928294e-05, 'vf_explained_var': 0.30231573681036633, 'kl': -6.671519915717434e-09, 'entropy': 7.97705312531131e-05, 'entropy_coeff': 0.0010000000000000002}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 3858.5, 'diff_num_grad_updates_vs_sampler_policy': 5.5}}, 'num_env_steps_sampled': 82432, 'num_env_steps_trained': 82432, 'num_agent_steps_sampled': 82432, 'num_agent_steps_trained': 82432}, 'sampler_results': {'episode_reward_max': 0.0, 'episode_reward_min': -40.90000000000031, 'episode_reward_mean': -0.9178571428571457, 'episode_len_mean': 977.5833333333334, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-40.90000000000031, -16.09999999999996, -8.099999999999987, -9.699999999999982, -1.9000000000000006, -0.1, -0.1, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [678, 382, 308, 669, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.6315373191609022, 'mean_inference_ms': 2.3072003199408733, 'mean_action_processing_ms': 0.23808655892424865, 'mean_env_wait_ms': 0.1623670528249735, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.010088511875697545, 'StateBufferConnector_ms': 0.0082484313419887, 'ViewRequirementAgentConnector_ms': 0.30311743418375653}}, 'episode_reward_max': 0.0, 'episode_reward_min': -40.90000000000031, 'episode_reward_mean': -0.9178571428571457, 'episode_len_mean': 977.5833333333334, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-40.90000000000031, -16.09999999999996, -8.099999999999987, -9.699999999999982, -1.9000000000000006, -0.1, -0.1, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [678, 382, 308, 669, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.6315373191609022, 'mean_inference_ms': 2.3072003199408733, 'mean_action_processing_ms': 0.23808655892424865, 'mean_env_wait_ms': 0.1623670528249735, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.010088511875697545, 'StateBufferConnector_ms': 0.0082484313419887, 'ViewRequirementAgentConnector_ms': 0.30311743418375653}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 82432, 'num_agent_steps_trained': 82432, 'num_env_steps_sampled': 82432, 'num_env_steps_trained': 82432, 'num_env_steps_sampled_this_iter': 256, 'num_env_steps_trained_this_iter': 256, 'num_env_steps_sampled_throughput_per_sec': 192.29555160365413, 'num_env_steps_trained_throughput_per_sec': 192.29555160365413, 'num_steps_trained_this_iter': 256, 'agent_timesteps_total': 82432, 'timers': {'training_iteration_time_ms': 886.038, 'sample_time_ms': 809.801, 'load_time_ms': 0.323, 'load_throughput': 792838.975, 'learn_time_ms': 75.468, 'learn_throughput': 3392.166, 'synch_weights_time_ms': 0.006}, 'counters': {'num_env_steps_sampled': 82432, 'num_env_steps_trained': 82432, 'num_agent_steps_sampled': 82432, 'num_agent_steps_trained': 82432}, 'done': False, 'trial_id': 'd3aa5_00006', 'perf': {'cpu_util_percent': 37.15, 'ram_util_percent': 61.2}, 'experiment_tag': '6_lr=0.0100,train_batch_size=256'},\n",
       "    path='/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00006_6_lr=0.0100,train_batch_size=256_2023-07-18_13-44-25',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    error='RayTaskError(RuntimeError)',\n",
       "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.960027813911438, 'cur_kl_coeff': 0.10000000000000002, 'cur_lr': 0.0010000000000000002, 'total_loss': 0.48997879307717085, 'policy_loss': -0.011656731367111206, 'vf_loss': 0.5025106854736805, 'vf_explained_var': -0.553967167933782, 'kl': 0.002026959796661787, 'entropy': 1.0778366923332214, 'entropy_coeff': 0.0010000000000000002}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 30.5, 'diff_num_grad_updates_vs_sampler_policy': 5.5}}, 'num_env_steps_sampled': 768, 'num_env_steps_trained': 768, 'num_agent_steps_sampled': 768, 'num_agent_steps_trained': 768}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 768, 'num_agent_steps_trained': 768, 'num_env_steps_sampled': 768, 'num_env_steps_trained': 768, 'num_env_steps_sampled_this_iter': 256, 'num_env_steps_trained_this_iter': 256, 'num_env_steps_sampled_throughput_per_sec': 172.5756966566268, 'num_env_steps_trained_throughput_per_sec': 172.5756966566268, 'num_steps_trained_this_iter': 256, 'agent_timesteps_total': 768, 'timers': {'training_iteration_time_ms': 1537.519, 'sample_time_ms': 1392.094, 'load_time_ms': 0.848, 'load_throughput': 301838.969, 'learn_time_ms': 143.679, 'learn_throughput': 1781.755, 'synch_weights_time_ms': 0.006}, 'counters': {'num_env_steps_sampled': 768, 'num_env_steps_trained': 768, 'num_agent_steps_sampled': 768, 'num_agent_steps_trained': 768}, 'done': False, 'trial_id': 'd3aa5_00007', 'perf': {'cpu_util_percent': 60.20000000000001, 'ram_util_percent': 62.43333333333334}, 'experiment_tag': '7_lr=0.0010,train_batch_size=256'},\n",
       "    path='/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00007_7_lr=0.0010,train_batch_size=256_2023-07-18_13-44-25',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.0158412807698672, 'cur_kl_coeff': 1.8726705418768797e-97, 'cur_lr': 0.0005000000000000001, 'total_loss': 4.753470420837402e-06, 'policy_loss': 2.2351741790771484e-08, 'vf_loss': 5.070262583709943e-06, 'vf_explained_var': 0.22794933120409647, 'kl': -1.0482155160139103e-09, 'entropy': 0.00035632081077589345, 'entropy_coeff': 0.0010000000000000002}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 3834.5, 'diff_num_grad_updates_vs_sampler_policy': 5.5}}, 'num_env_steps_sampled': 81920, 'num_env_steps_trained': 81920, 'num_agent_steps_sampled': 81920, 'num_agent_steps_trained': 81920}, 'sampler_results': {'episode_reward_max': 0.0, 'episode_reward_min': -51.700000000000465, 'episode_reward_mean': -3.7517241379310486, 'episode_len_mean': 935.3448275862069, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-25.200000000000088, -18.799999999999997, -24.200000000000074, -39.30000000000029, -37.50000000000026, -51.700000000000465, -8.499999999999986, -20.200000000000017, -12.89999999999997, -23.10000000000006, -12.099999999999973, -22.100000000000044, -7.19999999999999, -5.999999999999995, -4.5, -2.9000000000000012, -1.2, -1.8000000000000005, -2.2000000000000006, -0.9999999999999999, -0.9999999999999999, -0.5, -0.30000000000000004, -0.1, -0.5, -0.2, 0.0, 0.0, 0.0, -0.1, -0.1, 0.0, -0.1, 0.0, -0.1, 0.0, -0.1, 0.0, -0.1, -0.1, -0.1, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, -0.1, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, -0.1, 0.0, 0.0, 0.0], 'episode_lengths': [379, 298, 399, 603, 638, 1001, 196, 503, 388, 739, 584, 938, 1001, 689, 1001, 1001, 1001, 947, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.6237919083427825, 'mean_inference_ms': 2.362861271239322, 'mean_action_processing_ms': 0.25318955075826116, 'mean_env_wait_ms': 0.16052166065376836, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.01039806453660987, 'StateBufferConnector_ms': 0.00833971747036638, 'ViewRequirementAgentConnector_ms': 0.2486171393558897}}, 'episode_reward_max': 0.0, 'episode_reward_min': -51.700000000000465, 'episode_reward_mean': -3.7517241379310486, 'episode_len_mean': 935.3448275862069, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-25.200000000000088, -18.799999999999997, -24.200000000000074, -39.30000000000029, -37.50000000000026, -51.700000000000465, -8.499999999999986, -20.200000000000017, -12.89999999999997, -23.10000000000006, -12.099999999999973, -22.100000000000044, -7.19999999999999, -5.999999999999995, -4.5, -2.9000000000000012, -1.2, -1.8000000000000005, -2.2000000000000006, -0.9999999999999999, -0.9999999999999999, -0.5, -0.30000000000000004, -0.1, -0.5, -0.2, 0.0, 0.0, 0.0, -0.1, -0.1, 0.0, -0.1, 0.0, -0.1, 0.0, -0.1, 0.0, -0.1, -0.1, -0.1, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, -0.1, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, -0.1, 0.0, 0.0, 0.0], 'episode_lengths': [379, 298, 399, 603, 638, 1001, 196, 503, 388, 739, 584, 938, 1001, 689, 1001, 1001, 1001, 947, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.6237919083427825, 'mean_inference_ms': 2.362861271239322, 'mean_action_processing_ms': 0.25318955075826116, 'mean_env_wait_ms': 0.16052166065376836, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.01039806453660987, 'StateBufferConnector_ms': 0.00833971747036638, 'ViewRequirementAgentConnector_ms': 0.2486171393558897}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 81920, 'num_agent_steps_trained': 81920, 'num_env_steps_sampled': 81920, 'num_env_steps_trained': 81920, 'num_env_steps_sampled_this_iter': 256, 'num_env_steps_trained_this_iter': 256, 'num_env_steps_sampled_throughput_per_sec': 265.003462409204, 'num_env_steps_trained_throughput_per_sec': 265.003462409204, 'num_steps_trained_this_iter': 256, 'agent_timesteps_total': 81920, 'timers': {'training_iteration_time_ms': 861.167, 'sample_time_ms': 783.813, 'load_time_ms': 0.412, 'load_throughput': 621882.21, 'learn_time_ms': 76.473, 'learn_throughput': 3347.594, 'synch_weights_time_ms': 0.005}, 'counters': {'num_env_steps_sampled': 81920, 'num_env_steps_trained': 81920, 'num_agent_steps_sampled': 81920, 'num_agent_steps_trained': 81920}, 'done': False, 'trial_id': 'd3aa5_00008', 'perf': {'cpu_util_percent': 69.6, 'ram_util_percent': 61.2}, 'experiment_tag': '8_lr=0.0005,train_batch_size=256'},\n",
       "    path='/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00008_8_lr=0.0005,train_batch_size=256_2023-07-18_13-44-25',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.01955747545768342, 'cur_kl_coeff': 1.3301387766833225e-46, 'cur_lr': 0.01, 'total_loss': 7.996335625648499e-06, 'policy_loss': 3.787378470102946e-08, 'vf_loss': 8.088630117993508e-06, 'vf_explained_var': 0.7230750819047292, 'kl': 6.576528480301476e-10, 'entropy': 0.0001382438713335432, 'entropy_coeff': 0.001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 3972.5, 'diff_num_grad_updates_vs_sampler_policy': 11.5}}, 'num_env_steps_sampled': 84992, 'num_env_steps_trained': 84992, 'num_agent_steps_sampled': 84992, 'num_agent_steps_trained': 84992}, 'sampler_results': {'episode_reward_max': 0.0, 'episode_reward_min': -57.400000000000546, 'episode_reward_mean': -2.4461538461538495, 'episode_len_mean': 928.2857142857143, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-17.59999999999998, -57.400000000000546, -19.60000000000001, -15.89999999999996, -16.499999999999964, -15.69999999999996, -17.999999999999986, -10.399999999999979, -9.699999999999982, -10.699999999999978, -8.999999999999984, -5.599999999999996, -8.099999999999987, -4.799999999999999, -2.3000000000000007, -0.7, -0.2, 0.0, -0.2, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [259, 1001, 399, 342, 460, 502, 554, 381, 401, 409, 700, 626, 572, 791, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.595880801660869, 'mean_inference_ms': 2.360611172847669, 'mean_action_processing_ms': 0.2426259783235133, 'mean_env_wait_ms': 0.16624061665302212, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.011350820352742961, 'StateBufferConnector_ms': 0.00774179186139788, 'ViewRequirementAgentConnector_ms': 0.20030514224544987}}, 'episode_reward_max': 0.0, 'episode_reward_min': -57.400000000000546, 'episode_reward_mean': -2.4461538461538495, 'episode_len_mean': 928.2857142857143, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-17.59999999999998, -57.400000000000546, -19.60000000000001, -15.89999999999996, -16.499999999999964, -15.69999999999996, -17.999999999999986, -10.399999999999979, -9.699999999999982, -10.699999999999978, -8.999999999999984, -5.599999999999996, -8.099999999999987, -4.799999999999999, -2.3000000000000007, -0.7, -0.2, 0.0, -0.2, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [259, 1001, 399, 342, 460, 502, 554, 381, 401, 409, 700, 626, 572, 791, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.595880801660869, 'mean_inference_ms': 2.360611172847669, 'mean_action_processing_ms': 0.2426259783235133, 'mean_env_wait_ms': 0.16624061665302212, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.011350820352742961, 'StateBufferConnector_ms': 0.00774179186139788, 'ViewRequirementAgentConnector_ms': 0.20030514224544987}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 84992, 'num_agent_steps_trained': 84992, 'num_env_steps_sampled': 84992, 'num_env_steps_trained': 84992, 'num_env_steps_sampled_this_iter': 512, 'num_env_steps_trained_this_iter': 512, 'num_env_steps_sampled_throughput_per_sec': 264.07488642848875, 'num_env_steps_trained_throughput_per_sec': 264.07488642848875, 'num_steps_trained_this_iter': 512, 'agent_timesteps_total': 84992, 'timers': {'training_iteration_time_ms': 1708.22, 'sample_time_ms': 1543.466, 'load_time_ms': 0.401, 'load_throughput': 1275758.123, 'learn_time_ms': 163.847, 'learn_throughput': 3124.875, 'synch_weights_time_ms': 0.005}, 'counters': {'num_env_steps_sampled': 84992, 'num_env_steps_trained': 84992, 'num_agent_steps_sampled': 84992, 'num_agent_steps_trained': 84992}, 'done': False, 'trial_id': 'd3aa5_00009', 'perf': {'cpu_util_percent': 69.8, 'ram_util_percent': 61.2}, 'experiment_tag': '9_lr=0.0100,train_batch_size=512'},\n",
       "    path='/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00009_9_lr=0.0100,train_batch_size=512_2023-07-18_13-44-25',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.0070520824859462055, 'cur_kl_coeff': 6.842277657836022e-50, 'cur_lr': 0.001, 'total_loss': 5.901480714480082e-07, 'policy_loss': 6.20881716410319e-10, 'vf_loss': 9.862638711647758e-07, 'vf_explained_var': 0.05792701244354248, 'kl': 3.013823042286078e-09, 'entropy': 0.0003921416998006559, 'entropy_coeff': 0.001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 3972.5, 'diff_num_grad_updates_vs_sampler_policy': 11.5}}, 'num_env_steps_sampled': 84992, 'num_env_steps_trained': 84992, 'num_agent_steps_sampled': 84992, 'num_agent_steps_trained': 84992}, 'sampler_results': {'episode_reward_max': 0.0, 'episode_reward_min': -54.70000000000051, 'episode_reward_mean': -1.92674418604652, 'episode_len_mean': 976.7209302325581, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-20.40000000000002, -19.300000000000004, -54.70000000000051, -22.40000000000005, -30.20000000000016, -9.399999999999983, -3.900000000000002, -1.8000000000000005, -0.9999999999999999, -0.5, -1.0999999999999999, -0.1, -0.2, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [285, 309, 1001, 475, 847, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5925572172614968, 'mean_inference_ms': 2.3438906644540185, 'mean_action_processing_ms': 0.2539730126980808, 'mean_env_wait_ms': 0.16267179205828597, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.011313516040181005, 'StateBufferConnector_ms': 0.00825150068416152, 'ViewRequirementAgentConnector_ms': 0.20280826923459075}}, 'episode_reward_max': 0.0, 'episode_reward_min': -54.70000000000051, 'episode_reward_mean': -1.92674418604652, 'episode_len_mean': 976.7209302325581, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-20.40000000000002, -19.300000000000004, -54.70000000000051, -22.40000000000005, -30.20000000000016, -9.399999999999983, -3.900000000000002, -1.8000000000000005, -0.9999999999999999, -0.5, -1.0999999999999999, -0.1, -0.2, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [285, 309, 1001, 475, 847, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5925572172614968, 'mean_inference_ms': 2.3438906644540185, 'mean_action_processing_ms': 0.2539730126980808, 'mean_env_wait_ms': 0.16267179205828597, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.011313516040181005, 'StateBufferConnector_ms': 0.00825150068416152, 'ViewRequirementAgentConnector_ms': 0.20280826923459075}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 84992, 'num_agent_steps_trained': 84992, 'num_env_steps_sampled': 84992, 'num_env_steps_trained': 84992, 'num_env_steps_sampled_this_iter': 512, 'num_env_steps_trained_this_iter': 512, 'num_env_steps_sampled_throughput_per_sec': 309.85215401911967, 'num_env_steps_trained_throughput_per_sec': 309.85215401911967, 'num_steps_trained_this_iter': 512, 'agent_timesteps_total': 84992, 'timers': {'training_iteration_time_ms': 1701.357, 'sample_time_ms': 1554.699, 'load_time_ms': 0.399, 'load_throughput': 1283152.275, 'learn_time_ms': 145.823, 'learn_throughput': 3511.098, 'synch_weights_time_ms': 0.005}, 'counters': {'num_env_steps_sampled': 84992, 'num_env_steps_trained': 84992, 'num_agent_steps_sampled': 84992, 'num_agent_steps_trained': 84992}, 'done': False, 'trial_id': 'd3aa5_00010', 'perf': {'cpu_util_percent': 67.94999999999999, 'ram_util_percent': 61.2}, 'experiment_tag': '10_lr=0.0010,train_batch_size=512'},\n",
       "    path='/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00010_10_lr=0.0010,train_batch_size=512_2023-07-18_13-44-25',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    error='RayTaskError(RuntimeError)',\n",
       "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.9953919450441995, 'cur_kl_coeff': 0.10000000000000002, 'cur_lr': 0.0005, 'total_loss': 0.5192205410761138, 'policy_loss': -0.007994502938042084, 'vf_loss': 0.5282114930450916, 'vf_explained_var': -0.016719341278076172, 'kl': 0.0009595869848334956, 'entropy': 1.0924206028381984, 'entropy_coeff': 0.001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 36.5, 'diff_num_grad_updates_vs_sampler_policy': 11.5}}, 'num_env_steps_sampled': 1024, 'num_env_steps_trained': 1024, 'num_agent_steps_sampled': 1024, 'num_agent_steps_trained': 1024}, 'sampler_results': {'episode_reward_max': -24.800000000000082, 'episode_reward_min': -25.500000000000092, 'episode_reward_mean': -25.150000000000087, 'episode_len_mean': 387.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-25.500000000000092, -24.800000000000082], 'episode_lengths': [382, 392]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8682827948843799, 'mean_inference_ms': 3.805379168382981, 'mean_action_processing_ms': 0.4554470471964466, 'mean_env_wait_ms': 0.25697395928841327, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.012862682342529297, 'StateBufferConnector_ms': 0.00985860824584961, 'ViewRequirementAgentConnector_ms': 0.2619504928588867}}, 'episode_reward_max': -24.800000000000082, 'episode_reward_min': -25.500000000000092, 'episode_reward_mean': -25.150000000000087, 'episode_len_mean': 387.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-25.500000000000092, -24.800000000000082], 'episode_lengths': [382, 392]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8682827948843799, 'mean_inference_ms': 3.805379168382981, 'mean_action_processing_ms': 0.4554470471964466, 'mean_env_wait_ms': 0.25697395928841327, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.012862682342529297, 'StateBufferConnector_ms': 0.00985860824584961, 'ViewRequirementAgentConnector_ms': 0.2619504928588867}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 1024, 'num_agent_steps_trained': 1024, 'num_env_steps_sampled': 1024, 'num_env_steps_trained': 1024, 'num_env_steps_sampled_this_iter': 512, 'num_env_steps_trained_this_iter': 512, 'num_env_steps_sampled_throughput_per_sec': 172.98103799240263, 'num_env_steps_trained_throughput_per_sec': 172.98103799240263, 'num_steps_trained_this_iter': 512, 'agent_timesteps_total': 1024, 'timers': {'training_iteration_time_ms': 3031.005, 'sample_time_ms': 2732.929, 'load_time_ms': 0.471, 'load_throughput': 1087884.32, 'learn_time_ms': 297.024, 'learn_throughput': 1723.769, 'synch_weights_time_ms': 0.007}, 'counters': {'num_env_steps_sampled': 1024, 'num_env_steps_trained': 1024, 'num_agent_steps_sampled': 1024, 'num_agent_steps_trained': 1024}, 'done': False, 'trial_id': 'd3aa5_00011', 'perf': {'cpu_util_percent': 47.474999999999994, 'ram_util_percent': 62.5}, 'experiment_tag': '11_lr=0.0005,train_batch_size=512'},\n",
       "    path='/Users/adamprice/ray_results/PPO/PPO_cartpole_swingup_1_d3aa5_00011_11_lr=0.0005,train_batch_size=512_2023-07-18_13-44-25',\n",
       "    checkpoint=None\n",
       "  )\n",
       "]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = PPOConfig()\n",
    "config.training(lr=tune.grid_search([.01,0.001,0.0005]), num_sgd_iter=3, train_batch_size=tune.grid_search([64,128,256,512]), entropy_coeff=0.001, sgd_minibatch_size=64, lambda_=0.95,\n",
    "                model={\"fcnet_hiddens\": [32], \"fcnet_activation\": \"tanh\",})\n",
    "config.resources(num_cpus_per_worker=1)\n",
    "config.rollouts(num_rollout_workers=0)\n",
    "#config.exploration(explore=True, exploration_config={\"type\": \"RE3\", \"embeds_dim\": 32, \"beta_schedule\": \"constant\", \"sub_exploration\": {\"type\": \"StochasticSampling\",},})\n",
    "config.exploration(explore=True, exploration_config={   \n",
    "                    \"type\": \"Curiosity\",\n",
    "                    \"eta\": 0.2,\n",
    "                    \"lr\": 0.001,\n",
    "                    \"feature_dim\": 64,\n",
    "                    \"feature_net_config\": {\n",
    "                        \"fcnet_hiddens\": [],\n",
    "                        \"fcnet_activation\": \"relu\",\n",
    "                    },\n",
    "                    \"sub_exploration\": {\n",
    "                        \"type\": \"StochasticSampling\",\n",
    "                    }},)\n",
    "config.framework('torch')\n",
    "\n",
    "config.environment(env=env_str.replace('/','_'))  \n",
    "\n",
    "tune.Tuner(\n",
    "        \"PPO\",\n",
    "        run_config=air.RunConfig(stop={\"episodes_total\": env.bsuite_num_episodes}, verbose=2),\n",
    "        param_space=config.to_dict(),\n",
    "        ).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = DQNConfig()\n",
    "print(config.exploration_config)  # doctest: +SKIP\n",
    "        # >>> explore_config = config.exploration_config.update( # doctest: +SKIP\n",
    "        # ...     {\n",
    "        # ...         \"initial_epsilon\": 1.5,\n",
    "        # ...         \"final_epsilon\": 0.01,\n",
    "        # ...         \"epsilone_timesteps\": 5000,\n",
    "        # ...     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 15:49:27,882\tWARNING deprecation.py:50 -- DeprecationWarning: `rllib/algorithms/a3c/a3c.py` has been deprecated. Use `rllib_contrib/a3c/` instead. This will raise an error in the future!\n",
      "2023-07-17 15:49:27,883\tWARNING deprecation.py:50 -- DeprecationWarning: `rllib/algorithms/a3c/a3c.py` has been deprecated. Use `rllib_contrib/a3c/` instead. This will raise an error in the future!\n",
      "2023-07-17 15:49:28,016\tWARNING deprecation.py:50 -- DeprecationWarning: `rllib/algorithms/maml/maml.py` has been deprecated. Use `rllib_contrib/maml/` instead. This will raise an error in the future!\n",
      "2023-07-17 15:49:31,645\tINFO worker.py:1636 -- Started a local Ray instance.\n",
      "2023-07-17 15:49:33,567\tINFO tune.py:226 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
      "2023-07-17 15:49:33,572\tWARNING syncer.py:222 -- You are using remote storage, but you don't have `fsspec` installed. This can lead to inefficient syncing behavior. To avoid this, install fsspec with `pip install fsspec`. Depending on your remote storage provider, consider installing the respective fsspec-package (see https://github.com/fsspec).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-07-17 15:51:13</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:40.11        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.5/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/12 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_cartpole_swingup_15_24889_00000</td><td>RUNNING </td><td>127.0.0.1:44541</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         74.0885</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">               593</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=44541)\u001b[0m 2023-07-17 15:49:47,881\tWARNING algorithm_config.py:643 -- Cannot create DQNConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(DQN pid=44541)\u001b[0m 2023-07-17 15:49:47,946\tINFO algorithm.py:536 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=44541)\u001b[0m 2023-07-17 15:49:47,954\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(DQN pid=44541)\u001b[0m 2023-07-17 15:49:47,989\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=44541)\u001b[0m \u001b[1m\u001b[97mLoaded bsuite_id: cartpole_swingup/15.\u001b[0m\n",
      "\u001b[2m\u001b[36m(DQN pid=44541)\u001b[0m \u001b[1m\u001b[33mLogging results to SQLite database in /Users/adamprice/RLOlympics/results/PPO/data.db.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>connector_metrics                                                                                                                                              </th><th>counters                                                                                                                                                                                  </th><th>custom_metrics  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th>info  </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_sampled_throughput_per_sec</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained_throughput_per_sec</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                    </th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                     </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </th><th>timers                                                                                                                                                                                                  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_cartpole_swingup_15_24889_00000</td><td style=\"text-align: right;\">                   5000</td><td>{&#x27;ObsPreprocessorConnector_ms&#x27;: 0.009468623570033483, &#x27;StateBufferConnector_ms&#x27;: 0.008133479527064733, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.18689632415771484}</td><td>{&#x27;num_env_steps_sampled&#x27;: 5000, &#x27;num_env_steps_trained&#x27;: 32000, &#x27;num_agent_steps_sampled&#x27;: 5000, &#x27;num_agent_steps_trained&#x27;: 32000, &#x27;last_target_update_ts&#x27;: 4501, &#x27;num_target_updates&#x27;: 8}</td><td>{}              </td><td style=\"text-align: right;\">               593</td><td>{}             </td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                   1</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 0.0002231836406281218, &#x27;mean_q&#x27;: 0.010651863180100918, &#x27;min_q&#x27;: 0.0033542783930897713, &#x27;max_q&#x27;: 0.014367694035172462, &#x27;cur_lr&#x27;: 0.0005}, &#x27;td_error&#x27;: array([-1.8708613e-03, -2.0321333e-03,  4.2565912e-04, -1.3950374e-03,\n",
       "        1.1789147e-05, -2.4231616e-04, -1.8147901e-03, -1.1783671e-03],\n",
       "      dtype=float32), &#x27;mean_td_error&#x27;: -0.0010120071237906814, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 8.0, &#x27;num_grad_updates_lifetime&#x27;: 4000.0, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 2106.75}}, &#x27;num_env_steps_sampled&#x27;: 5000, &#x27;num_env_steps_trained&#x27;: 32000, &#x27;num_agent_steps_sampled&#x27;: 5000, &#x27;num_agent_steps_trained&#x27;: 32000, &#x27;last_target_update_ts&#x27;: 4501, &#x27;num_target_updates&#x27;: 8}       </td><td style=\"text-align: right;\">                     5000</td><td style=\"text-align: right;\">                    32000</td><td style=\"text-align: right;\">                   5000</td><td style=\"text-align: right;\">                             1000</td><td style=\"text-align: right;\">                                   57.9062</td><td style=\"text-align: right;\">                  32000</td><td style=\"text-align: right;\">                             8000</td><td style=\"text-align: right;\">                                    463.25</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                         8000</td><td>{&#x27;cpu_util_percent&#x27;: 17.928, &#x27;ram_util_percent&#x27;: 65.708}</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 1.1539095872074483, &#x27;mean_inference_ms&#x27;: 2.1743713638976483, &#x27;mean_action_processing_ms&#x27;: 0.17567318191922615, &#x27;mean_env_wait_ms&#x27;: 0.13429271315136998, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 0.0, &#x27;episode_reward_min&#x27;: 0.0, &#x27;episode_reward_mean&#x27;: 0.0, &#x27;episode_len_mean&#x27;: 593.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 1, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], &#x27;episode_lengths&#x27;: [985, 250, 549, 935, 363, 284, 785]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 1.1539095872074483, &#x27;mean_inference_ms&#x27;: 2.1743713638976483, &#x27;mean_action_processing_ms&#x27;: 0.17567318191922615, &#x27;mean_env_wait_ms&#x27;: 0.13429271315136998, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: 0.009468623570033483, &#x27;StateBufferConnector_ms&#x27;: 0.008133479527064733, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.18689632415771484}}</td><td>{&#x27;training_iteration_time_ms&#x27;: 17.681, &#x27;sample_time_ms&#x27;: 4.023, &#x27;load_time_ms&#x27;: 0.247, &#x27;load_throughput&#x27;: 32454.233, &#x27;learn_time_ms&#x27;: 8.463, &#x27;learn_throughput&#x27;: 945.27, &#x27;synch_weights_time_ms&#x27;: 0.035}</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 15:51:13,744\tWARNING tune.py:192 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2023-07-17 15:51:21,149\tINFO tune.py:1111 -- Total run time: 107.58 seconds (100.11 seconds for the tuning loop).\n",
      "2023-07-17 15:51:21,150\tWARNING tune.py:1126 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/Users/adamprice/ray_results/DQN\", trainable=...)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResultGrid<[\n",
       "  Result(\n",
       "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.0002231836406281218, 'mean_q': 0.010651863180100918, 'min_q': 0.0033542783930897713, 'max_q': 0.014367694035172462, 'cur_lr': 0.0005}, 'td_error': array([-1.8708613e-03, -2.0321333e-03,  4.2565912e-04, -1.3950374e-03,\n",
       "        1.1789147e-05, -2.4231616e-04, -1.8147901e-03, -1.1783671e-03],\n",
       "      dtype=float32), 'mean_td_error': -0.0010120071237906814, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 8.0, 'num_grad_updates_lifetime': 4000.0, 'diff_num_grad_updates_vs_sampler_policy': 2106.75}}, 'num_env_steps_sampled': 5000, 'num_env_steps_trained': 32000, 'num_agent_steps_sampled': 5000, 'num_agent_steps_trained': 32000, 'last_target_update_ts': 4501, 'num_target_updates': 8}, 'sampler_results': {'episode_reward_max': 0.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 0.0, 'episode_len_mean': 593.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [985, 250, 549, 935, 363, 284, 785]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.1539095872074483, 'mean_inference_ms': 2.1743713638976483, 'mean_action_processing_ms': 0.17567318191922615, 'mean_env_wait_ms': 0.13429271315136998, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.009468623570033483, 'StateBufferConnector_ms': 0.008133479527064733, 'ViewRequirementAgentConnector_ms': 0.18689632415771484}}, 'episode_reward_max': 0.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 0.0, 'episode_len_mean': 593.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [985, 250, 549, 935, 363, 284, 785]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.1539095872074483, 'mean_inference_ms': 2.1743713638976483, 'mean_action_processing_ms': 0.17567318191922615, 'mean_env_wait_ms': 0.13429271315136998, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.009468623570033483, 'StateBufferConnector_ms': 0.008133479527064733, 'ViewRequirementAgentConnector_ms': 0.18689632415771484}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 5000, 'num_agent_steps_trained': 32000, 'num_env_steps_sampled': 5000, 'num_env_steps_trained': 32000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 8000, 'num_env_steps_sampled_throughput_per_sec': 57.906209122408164, 'num_env_steps_trained_throughput_per_sec': 463.2496729792653, 'num_steps_trained_this_iter': 8000, 'agent_timesteps_total': 5000, 'timers': {'training_iteration_time_ms': 17.681, 'sample_time_ms': 4.023, 'load_time_ms': 0.247, 'load_throughput': 32454.233, 'learn_time_ms': 8.463, 'learn_throughput': 945.27, 'synch_weights_time_ms': 0.035}, 'counters': {'num_env_steps_sampled': 5000, 'num_env_steps_trained': 32000, 'num_agent_steps_sampled': 5000, 'num_agent_steps_trained': 32000, 'last_target_update_ts': 4501, 'num_target_updates': 8}, 'done': False, 'trial_id': '24889_00000', 'perf': {'cpu_util_percent': 17.928, 'ram_util_percent': 65.708}, 'experiment_tag': '0'},\n",
       "    path='/Users/adamprice/ray_results/DQN/DQN_cartpole_swingup_15_24889_00000_0_2023-07-17_15-49-33',\n",
       "    checkpoint=None\n",
       "  )\n",
       "]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "config = DQNConfig()\n",
    "config.training(train_batch_size=8,\n",
    "                model={\"fcnet_hiddens\": [32, 32], \"fcnet_activation\": \"tanh\",})\n",
    "config.resources(num_cpus_per_worker=1)\n",
    "config.rollouts(num_rollout_workers=0)\n",
    "config.exploration(explore=True, exploration_config={\"type\": \"SoftQ\", \"temperature\": 1.0})\n",
    "config.framework('torch')\n",
    "\n",
    "config.environment(env=env_str.replace('/','_'))  \n",
    "\n",
    "tune.Tuner(\n",
    "        \"DQN\",\n",
    "        run_config=air.RunConfig(stop={\"episodes_total\": env.bsuite_num_episodes}, verbose=2),\n",
    "        param_space=config.to_dict(),\n",
    "        ).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Callable, Mapping, NamedTuple, Sequence\n",
    "\n",
    "class BSuiteSummary(NamedTuple):\n",
    "  \"\"\"Container for summary metadata for a given bsuite experiment.\"\"\"\n",
    "  score: Callable[[pd.DataFrame], float]\n",
    "  type: str\n",
    "  tags: Sequence[str]\n",
    "  episode: int\n",
    "\n",
    "\n",
    "def _is_finished(df: pd.DataFrame, n_min: int) -> bool:\n",
    "  \"\"\"Check to see if every bsuite id in the dataframe is finished.\"\"\"\n",
    "  # At this point we have grouped by any additional hyperparameters.\n",
    "  # Check if we have run enough episodes for every id.\n",
    "  max_time = df.groupby('bsuite_id')['episode'].max().reset_index()\n",
    "  return max_time['episode'].min() >= n_min\n",
    "\n",
    "def _bsuite_score_single(df: pd.DataFrame,\n",
    "                         experiment_info: Mapping[str, BSuiteSummary],\n",
    "                         verbose: bool = False) -> pd.DataFrame:\n",
    "  \"\"\"Score the bsuite across all domains for a single agent.\"\"\"\n",
    "  data = []\n",
    "  for env_name, env_data in df.groupby('bsuite_env'):\n",
    "    if env_name not in experiment_info:\n",
    "      if verbose:\n",
    "        print('WARNING: {}_score not found in load.py and so is excluded.'\n",
    "              .format(env_name))\n",
    "    else:\n",
    "      b_summary = experiment_info[env_name]\n",
    "      data.append({\n",
    "          'bsuite_env': env_name,\n",
    "          'score': b_summary.score(env_data),\n",
    "          'type': b_summary.type,\n",
    "          'tags': str(b_summary.tags),\n",
    "          'finished': _is_finished(env_data, b_summary.episode),\n",
    "      })\n",
    "  return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: cartpole_swingup_score not found in load.py and so is excluded.\n",
      "WARNING: catch_score not found in load.py and so is excluded.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from bsuite.logging import sqlite_load\n",
    "# Create your connection.\n",
    "cnx = sqlite3.connect('/Users/adamprice/RLOlympics/results/PPO/data.db')\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM cartpole_swingup\", cnx)\n",
    "\n",
    "from bsuite.experiments.cartpole_swingup.analysis import score\n",
    "from bsuite.experiments.summary_analysis import BSUITE_INFO\n",
    "\n",
    "experiments = {'results/PPO/data.db'}  # Add results here\n",
    "DF, SWEEP_VARS = sqlite_load.load_bsuite(experiments)\n",
    "\n",
    "\n",
    "_bsuite_score_single(df, BSUITE_INFO, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of tables\n",
      "\n",
      "[('cartpole_swingup',), ('catch',)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Getting all tables from sqlite_master\n",
    "sql_query = \"\"\"SELECT name FROM sqlite_master\n",
    "WHERE type='table';\"\"\"\n",
    "\n",
    "# Creating cursor object using connection object\n",
    "cursor = cnx.cursor()\n",
    "    \n",
    "# executing our sql query\n",
    "cursor.execute(sql_query)\n",
    "print(\"List of tables\\n\")\n",
    "    \n",
    "# printing all tables list\n",
    "print(cursor.fetchall())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlolympics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
